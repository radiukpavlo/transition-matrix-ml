{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vex99np2wFVt"
   },
   "source": [
    "# 03. PyTorch Computer Vision Exercise Solutions\n",
    "\n",
    "The following is one possible set (there may be more than one way to do things) of solutions for the 03. PyTorch Computer Vision exercise template.\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises/solutions are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
    "  * **Note:** Going through these exercises took me just over 3 hours, so you should expect around the same.\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1690805496136,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "GaeYzOTLwWh2",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:58.348582900Z",
     "start_time": "2023-08-03T12:46:58.336615100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Check for GPU\\n!nvidia-smi'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Check for GPU\n",
    "!nvidia-smi'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1690805501014,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "6f485cb7-2edc-4e09-d1dd-79af23a6052a",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.317955700Z",
     "start_time": "2023-08-03T12:46:58.344594200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFX7tc1w-en"
   },
   "source": [
    "## 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmB6iAzN1X4u"
   },
   "source": [
    "1. Self-driving cars, such as Tesla using computer vision to percieve what's happening on the road. See Tesla AI day for more - https://youtu.be/j0z4FweCy4M\n",
    "2. Healthcare imaging, such as using computer vision to help interpret X-rays. Google also uses computer vision for detecting polyps in the intenstines - https://ai.googleblog.com/2021/08/improved-detection-of-elusive-polyps.html\n",
    "3. Security, computer vision can be used to detect whether someone is invading your home or not - https://store.google.com/au/product/nest_cam_battery?hl=en-GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBK-WI6YxDYa"
   },
   "source": [
    "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMLaps1J3pJ_"
   },
   "source": [
    "Overfitting is like memorizing for a test, but then you can't answer a question that's slightly different.\n",
    "\n",
    "In other words, if a model is overfitting, it's learning the training data *too well* and these patterns don't generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYFEqw8xK26"
   },
   "source": [
    "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
    "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9Hdd08s4kvN"
   },
   "source": [
    "See this article for some ideas: https://elitedatascience.com/overfitting-in-machine-learning\n",
    "\n",
    "3 ways to prevent overfitting:\n",
    "1. **Regularization techniques** - You could use [dropout on your neural networks](https://en.wikipedia.org/wiki/Dilution_(neural_networks)), dropout involves randomly removing neurons in different layers so that the remaining neurons hopefully learn more robust weights/patterns.\n",
    "2. **Use a different model** - maybe the model you're using for a specific problem is too complicated, as in, it's learning the data too well because it has so many layers. You could remove some layers to simplify your model. Or you could pick a totally different model altogether, one that may be more suited to your particular problem. Or... you could also use [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) (taking the patterns from one model and applying them to your own problem).\n",
    "3. **Reduce noise in data/cleanup dataset/introduce data augmentation techniques** - If the model is learning the data too well, it might be just memorizing the data, including the noise. One option would be to remove the noise/clean up the dataset or if this doesn't, you can introduce artificial noise through the use of data augmentation to artificially increase the diversity of your training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKdEEFEqxM-8"
   },
   "source": [
    "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnUox1qayDes"
   },
   "source": [
    "The CNN explainer website is a great insight into all the nuts and bolts of a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf-3pODxXYI"
   },
   "source": [
    "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690805501014,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "rV7s2qtIyDIZ",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.491066300Z",
     "start_time": "2023-08-03T12:46:59.289754200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1690805502075,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "tVnyuGku9m0y",
    "outputId": "642c8856-c82e-41da-8944-026a7fa3d96a",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.554863300Z",
     "start_time": "2023-08-03T12:46:59.495056700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset not found. Downloading to ../mnist/\n",
      "MNIST dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the paths\n",
    "check_path = './mnist/MNIST/raw'\n",
    "download_path = '../mnist/'\n",
    "\n",
    "# Check if MNIST dataset exists in the specified path\n",
    "if not os.path.exists(check_path):\n",
    "    print(\"MNIST dataset not found. Downloading to\", download_path)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # Download and load the MNIST train dataset\n",
    "    train_data = datasets.MNIST(root=download_path,\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transform)\n",
    "\n",
    "    # Download and load the MNIST test dataset\n",
    "    test_data = datasets.MNIST(root=download_path,\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=transform)\n",
    "    print(\"MNIST dataset downloaded successfully.\")\n",
    "else:\n",
    "    print(\"MNIST dataset found in\", check_path)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # Load the MNIST train dataset from the local path\n",
    "    train_data = datasets.MNIST(root=download_path,\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=transform)\n",
    "\n",
    "    # Load the MNIST test dataset from the local path\n",
    "    test_data = datasets.MNIST(root=download_path,\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "    print(\"MNIST dataset loaded from\", check_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1690805502076,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "yaj7vnOv-cB2",
    "outputId": "9fc4bdf8-aef2-4b13-cb5c-bac8f532fd96",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.597747700Z",
     "start_time": "2023-08-03T12:46:59.554863300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(Dataset MNIST\n     Number of datapoints: 60000\n     Root location: ../mnist/\n     Split: Train\n     StandardTransform\n Transform: Compose(\n                ToTensor()\n            ),\n Dataset MNIST\n     Number of datapoints: 10000\n     Root location: ../mnist/\n     Split: Test\n     StandardTransform\n Transform: Compose(\n                ToTensor()\n            ))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1690805502076,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "SUZMY9xR-sfH",
    "outputId": "0d90f988-6e12-4079-ad9c-b7e616fc1247",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.611710700Z",
     "start_time": "2023-08-03T12:46:59.570819800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 10000)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1690805502076,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "THsDkX0K-gUk",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.612708700Z",
     "start_time": "2023-08-03T12:46:59.584782900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'# Data is in tuple form (image, label)\\nimg = train_data[2][0]\\nlabel = train_data[2][1]\\nprint(f\"Image:\\n {img}\")\\nprint(f\"Label:\\n {label}\")\\n\\n# Check out the shapes of our data\\nprint(f\"Image shape: {img.shape} -> [color_channels, height, width] (CHW)\")\\nprint(f\"Label: {label} -> no shape, due to being integer\")'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Data is in tuple form (image, label)\n",
    "img = train_data[2][0]\n",
    "label = train_data[2][1]\n",
    "print(f\"Image:\\n {img}\")\n",
    "print(f\"Label:\\n {label}\")\n",
    "\n",
    "# Check out the shapes of our data\n",
    "print(f\"Image shape: {img.shape} -> [color_channels, height, width] (CHW)\")\n",
    "print(f\"Label: {label} -> no shape, due to being integer\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS3XHDW6AuJs"
   },
   "source": [
    "Note: There are two main agreed upon ways for representing images in machine learning:\n",
    "1. Color channels first: [color_channels, height, width] (CHW) -> PyTorch default (as of April 2022)\n",
    "2. Color channels last: [height, width, color_channels] (HWC) -> Matplotlib/TensorFlow default (as of April 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1690805502076,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "T7UEVf8B_JuK",
    "outputId": "66545de9-d5a7-433c-8409-bf53a7f6aabb",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.641630200Z",
     "start_time": "2023-08-03T12:46:59.599742500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['0 - zero',\n '1 - one',\n '2 - two',\n '3 - three',\n '4 - four',\n '5 - five',\n '6 - six',\n '7 - seven',\n '8 - eight',\n '9 - nine']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the class names from the dataset\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxZW-uAbxe_F"
   },
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1690805502077,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "HdRM86voyC0x",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.929806900Z",
     "start_time": "2023-08-03T12:46:59.616697300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'for i in range(5):\\n  img = train_data[i][0]\\n  print(img.shape)\\n  img_squeeze = img.squeeze()\\n  print(img_squeeze.shape)\\n  label = train_data[i][1]\\n  plt.figure(figsize=(3, 3))\\n  plt.imshow(img_squeeze, cmap=\"gray\")\\n  plt.title(label)\\n  plt.axis(False)'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''for i in range(5):\n",
    "  img = train_data[i][0]\n",
    "  print(img.shape)\n",
    "  img_squeeze = img.squeeze()\n",
    "  print(img_squeeze.shape)\n",
    "  label = train_data[i][1]\n",
    "  plt.figure(figsize=(3, 3))\n",
    "  plt.imshow(img_squeeze, cmap=\"gray\")\n",
    "  plt.title(label)\n",
    "  plt.axis(False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPDzW0wxhi3"
   },
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1690805502077,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "Cz09bv8KCnCa",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.975022Z",
     "start_time": "2023-08-03T12:46:59.930804700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create train dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=16,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=16,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1690805502077,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "8tWfa7Y0yCkX",
    "outputId": "24f1cb50-fa16-43c1-befe-dbe50f84871f",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.986990400Z",
     "start_time": "2023-08-03T12:46:59.946574200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(<torch.utils.data.dataloader.DataLoader at 0x16ed0cd1d30>,\n <torch.utils.data.dataloader.DataLoader at 0x16ed20610d0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1690805502077,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "z2-3iYEgD8K-",
    "outputId": "54d98ea6-8bc4-4bb3-b5c3-2202de665888",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:46:59.987987500Z",
     "start_time": "2023-08-03T12:46:59.962057100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for sample in next(iter(train_dataloader)):\n",
    "  print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690805502077,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "BfSrUoa9Eb3V",
    "outputId": "25452e5b-2005-4633-da31-bab133191e8c",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.021896100Z",
     "start_time": "2023-08-03T12:46:59.977017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(3750, 625)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCVfXk5xjYS"
   },
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1690805503056,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "xeBNV2AtyCP6",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.068770400Z",
     "start_time": "2023-08-03T12:46:59.996962700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from torch import nn\\n\\nclass MNISTModel(torch.nn.Module):\\n  \"\"\"Model capable of predicting on MNIST dataset.\\n  \"\"\"\\n  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\\n    super().__init__()\\n    self.conv_block_1 = nn.Sequential(\\n      nn.Conv2d(in_channels=input_shape,\\n                out_channels=hidden_units,\\n                kernel_size=3,\\n                stride=1,\\n                padding=1),\\n      nn.ReLU(),\\n      nn.Conv2d(in_channels=hidden_units,\\n                out_channels=hidden_units,\\n                kernel_size=3,\\n                stride=1,\\n                padding=1),\\n      nn.ReLU(),\\n      nn.MaxPool2d(kernel_size=2)\\n    )\\n    self.conv_block_2 = nn.Sequential(\\n      nn.Conv2d(in_channels=hidden_units,\\n                out_channels=hidden_units,\\n                kernel_size=3,\\n                stride=1,\\n                padding=1),\\n      nn.ReLU(),\\n      nn.Conv2d(in_channels=hidden_units,\\n                out_channels=hidden_units,\\n                kernel_size=3,\\n                stride=1,\\n                padding=1),\\n      nn.ReLU(),\\n      nn.MaxPool2d(kernel_size=2)\\n    )\\n    self.classifier = nn.Sequential(\\n      nn.Flatten(),\\n      nn.Linear(in_features=hidden_units*7*7,\\n                out_features=output_shape)\\n    )\\n\\n  def forward(self, x):\\n    \"\"\"\\n\\n    :param x:\\n    :return:\\n    \"\"\"\\n    x = self.conv_block_1(x)\\n    # print(f\"Output shape of conv block 1: {x.shape}\")\\n    x = self.conv_block_2(x)\\n    # print(f\"Output shape of conv block 2: {x.shape}\")\\n    # Before applying classifier, just flatten and print the shape\\n    x_flattened = nn.Flatten()(x) # Flatten the tensor\\n    self.get_flatten = nn.Flatten()(x) # flatten and save to a class attribute\\n    # print(f\"Shape after flattening: {x_flattened.shape}\")\\n    x = self.classifier(x)\\n    # print(f\"Output shape of classifier: {x.shape}\")\\n    return x'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from torch import nn\n",
    "\n",
    "class MNISTModel(torch.nn.Module):\n",
    "  \"\"\"Model capable of predicting on MNIST dataset.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=hidden_units*7*7,\n",
    "                out_features=output_shape)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = self.conv_block_1(x)\n",
    "    # print(f\"Output shape of conv block 1: {x.shape}\")\n",
    "    x = self.conv_block_2(x)\n",
    "    # print(f\"Output shape of conv block 2: {x.shape}\")\n",
    "    # Before applying classifier, just flatten and print the shape\n",
    "    x_flattened = nn.Flatten()(x) # Flatten the tensor\n",
    "    self.get_flatten = nn.Flatten()(x) # flatten and save to a class attribute\n",
    "    # print(f\"Shape after flattening: {x_flattened.shape}\")\n",
    "    x = self.classifier(x)\n",
    "    # print(f\"Output shape of classifier: {x.shape}\")\n",
    "    return x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNISTModel(torch.nn.Module):\n",
    "  \"\"\"Model capable of predicting on MNIST dataset.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=hidden_units*7*7,\n",
    "                out_features=output_shape)\n",
    "    )\n",
    "\n",
    "  def forward(self, x, return_flattened=False):\n",
    "    \"\"\"\n",
    "    :param return_flattened: \n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = self.conv_block_1(x)\n",
    "    # print(f\"Output shape of conv block 1: {x.shape}\")\n",
    "    x = self.conv_block_2(x)\n",
    "    # print(f\"Output shape of conv block 2: {x.shape}\")\n",
    "    # Before applying classifier, just flatten and print the shape\n",
    "    x_flattened = nn.Flatten()(x) # Flatten the tensor\n",
    "    # self.get_flatten = nn.Flatten()(x) # flatten and save to a class attribute\n",
    "    # print(f\"Shape after flattening: {x_flattened.shape}\")\n",
    "    x = self.classifier(x)\n",
    "    # print(f\"Output shape of classifier: {x.shape}\")\n",
    "    if return_flattened:\n",
    "        return x, x_flattened\n",
    "    else:\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.087720100Z",
     "start_time": "2023-08-03T12:47:00.016909900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1690805503057,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "Pfk9zykYK0FM",
    "outputId": "b257e814-4ccc-4766-e019-3b47a8cd2cb0",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.088717400Z",
     "start_time": "2023-08-03T12:47:00.025885700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4412,
     "status": "ok",
     "timestamp": 1690805507466,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "tPmadzsTJndN",
    "outputId": "599bad6a-ac98-41d2-b6e2-8ef6fa4a1207",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.103678900Z",
     "start_time": "2023-08-03T12:47:00.040845300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MNISTModel(\n  (conv_block_1): Sequential(\n    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_block_2): Sequential(\n    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=490, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTModel(input_shape=1,\n",
    "                    hidden_units=10,\n",
    "                    output_shape=10).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8281,
     "status": "ok",
     "timestamp": 1690805515743,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "bkFZjQR_mIQP",
    "outputId": "dbf74a87-6ac8-43bf-ef65-00bc4791496d",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.105671900Z",
     "start_time": "2023-08-03T12:47:00.056803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0168,  0.0144,  0.0397, -0.0134,  0.0819, -0.0185, -0.0221, -0.0710,\n         -0.0778,  0.0795]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random input tensor with the shape that matches a single MNIST image (1, 28, 28)\n",
    "# Note: The first 1 is the batch size, indicating we're feeding 1 image.\n",
    "my_input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
    "print(my_input_tensor.shape)\n",
    "\n",
    "# Pass the input tensor through the model to print the output shapes of each block\n",
    "my_output = model(my_input_tensor)\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690805515743,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "ExNGpLz9LfOO",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.105671900Z",
     "start_time": "2023-08-03T12:47:00.070765200Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Check out the model state dict to find out what patterns our model wants to learn\n",
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690805515743,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "6vqiDj2wmIQQ",
    "outputId": "6f9625b8-b3ea-4d68-bc80-b6fd0f3f08b6",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.194434600Z",
     "start_time": "2023-08-03T12:47:00.088717400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0165,  0.0249, -0.0343,  ...,  0.0120,  0.0337,  0.0416],\n",
      "        [-0.0107, -0.0230, -0.0333,  ...,  0.0206,  0.0399,  0.0132],\n",
      "        [ 0.0007,  0.0231, -0.0370,  ...,  0.0084, -0.0222, -0.0184],\n",
      "        ...,\n",
      "        [ 0.0357, -0.0100, -0.0121,  ...,  0.0292,  0.0160, -0.0386],\n",
      "        [ 0.0437,  0.0231, -0.0210,  ...,  0.0026, -0.0099, -0.0029],\n",
      "        [ 0.0369,  0.0069,  0.0123,  ..., -0.0264, -0.0234,  0.0439]])\n",
      "tensor([-3.3459e-02, -7.2405e-05, -2.6686e-03, -3.2682e-02,  1.7335e-02,\n",
      "        -2.0636e-02,  1.6978e-02, -9.2565e-03, -8.7553e-04, -3.2800e-03])\n"
     ]
    }
   ],
   "source": [
    "weights = model.classifier[1].weight.data\n",
    "bias = model.classifier[1].bias.data\n",
    "\n",
    "print(weights)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690805515744,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "AAd-DhBIMQ_N",
    "outputId": "41539813-ac24-4f70-e981-79dbe75a82d4",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.231336300Z",
     "start_time": "2023-08-03T12:47:00.103678900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.0035,  0.0343,  0.0110, -0.0074,  0.0720, -0.0106, -0.0056, -0.0656,\n         -0.0676,  0.0980]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a dummy forward pass to see what shapes our data is\n",
    "dummy_x = torch.rand(size=(1, 28, 28)).unsqueeze(dim=0).to(device)\n",
    "\n",
    "print(dummy_x.shape)\n",
    "model(dummy_x)\n",
    "# dummy_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1690805515744,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "xw4nqMCVN_Jr",
    "outputId": "1ae808b8-bf86-4f09-e3b5-c7f1ae24f102",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.233330800Z",
     "start_time": "2023-08-03T12:47:00.117640200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10, 7, 7])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x_2 = torch.rand(size=([1, 10, 7, 7]))\n",
    "dummy_x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1690805515744,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "9omFrrBCODLL",
    "outputId": "522bff81-bb6f-4962-e43f-de93fcd8d9b3",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.235325500Z",
     "start_time": "2023-08-03T12:47:00.133597900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 490])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer = nn.Flatten()\n",
    "flatten_layer(dummy_x_2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkE8puBImIQR"
   },
   "source": [
    "## 9. Train the model you built in exercise 8 for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1690805515744,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "in8DzC6tmIQR",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:47:00.236322900Z",
     "start_time": "2023-08-03T12:47:00.149554800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'%%time\\nfrom tqdm.auto import tqdm\\n\\n# Train on CPU\\nmodel_cpu = MNISTModel(input_shape=1,\\n                        hidden_units=10,\\n                        output_shape=10).to(\"cpu\")\\n\\n# Create a loss function and optimizer\\nloss_fn = nn.CrossEntropyLoss()\\noptimizer = torch.optim.SGD(model_cpu.parameters(), lr=0.1)\\n\\n### Training loop\\nepochs = 5\\nfor epoch in tqdm(range(epochs)):\\n  train_loss = 0\\n  for batch, (X, y) in enumerate(train_dataloader):\\n    model_cpu.train()\\n\\n    # Put data on CPU\\n    X, y = X.to(\"cpu\"), y.to(\"cpu\")\\n\\n    # Forward pass\\n    y_pred = model_cpu(X)\\n\\n    # Loss calculation\\n    loss = loss_fn(y_pred, y)\\n    train_loss += loss\\n\\n    # Optimizer zero grad\\n    optimizer.zero_grad()\\n\\n    # Loss backward\\n    loss.backward()\\n\\n    # Step the optimizer\\n    optimizer.step()\\n\\n  # Adjust train loss for number of batches\\n  train_loss /= len(train_dataloader)\\n\\n  ### Testing loop\\n  test_loss_total = 0\\n\\n  # Put model in eval mode\\n  model_cpu.eval()\\n\\n  # Turn on inference mode\\n  with torch.inference_mode():\\n    for batch, (X_test, y_test) in enumerate(test_dataloader):\\n      # Make sure test data on CPU\\n      X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\\n      test_pred = model_cpu(X_test)\\n      test_loss = loss_fn(test_pred, y_test)\\n\\n      test_loss_total += test_loss\\n\\n    test_loss_total /= len(test_dataloader)\\n\\n  # Print out what\\'s happening\\n  print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Train on CPU\n",
    "model_cpu = MNISTModel(input_shape=1,\n",
    "                        hidden_units=10,\n",
    "                        output_shape=10).to(\"cpu\")\n",
    "\n",
    "# Create a loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_cpu.parameters(), lr=0.1)\n",
    "\n",
    "### Training loop\n",
    "epochs = 5\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  train_loss = 0\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    model_cpu.train()\n",
    "\n",
    "    # Put data on CPU\n",
    "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model_cpu(X)\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "\n",
    "    # Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust train loss for number of batches\n",
    "  train_loss /= len(train_dataloader)\n",
    "\n",
    "  ### Testing loop\n",
    "  test_loss_total = 0\n",
    "\n",
    "  # Put model in eval mode\n",
    "  model_cpu.eval()\n",
    "\n",
    "  # Turn on inference mode\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "      # Make sure test data on CPU\n",
    "      X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\n",
    "      test_pred = model_cpu(X_test)\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "    test_loss_total /= len(test_dataloader)\n",
    "\n",
    "  # Print out what's happening\n",
    "  print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b2be661e7414444eafefc50786dd9b76",
      "2239f77486f348f989463de8eee7fbe9",
      "635e558c36e8415cafe69e315c70d1dd",
      "d73b703d06ee496781d48080e82edcd7",
      "04ed2a1850624ea3a724daf1f82c5383",
      "96f1ccc77d3641718bf41245e0c1c8c1",
      "fac90735353a4755935a42a125a72a73",
      "2691f9aec2614a1298133154a552dc71",
      "11b3193c755d4b91becf14efa1c443f0",
      "540f82a2be3d4f629c6a6f0b2713fa07",
      "b89e38295f934a4785756a4741ab1055"
     ]
    },
    "executionInfo": {
     "elapsed": 54986,
     "status": "ok",
     "timestamp": 1690805570724,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "0IzzuVLkPE9j",
    "outputId": "4007733b-461f-4a00-bb9d-b636db10f0cb",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.533677200Z",
     "start_time": "2023-08-03T12:47:00.167507500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:18<02:50, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.209 | Test loss: 0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:37<02:28, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 0.067 | Test loss: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:55<02:08, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 0.053 | Test loss: 0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:14<01:50, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 0.049 | Test loss: 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:32<01:31, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 0.045 | Test loss: 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:51<01:15, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 0.040 | Test loss: 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:09<00:55, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 0.038 | Test loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:27<00:36, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 0.035 | Test loss: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:45<00:18, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 0.034 | Test loss: 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:03<00:00, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.031 | Test loss: 0.034\n",
      "CPU times: total: 26min 45s\n",
      "Wall time: 3min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_weights_path = \"../model_weights/\"\n",
    "\n",
    "# Train on GPU\n",
    "model_gpu = MNISTModel(input_shape=1,\n",
    "                        hidden_units=10,\n",
    "                        output_shape=10).to(device)\n",
    "\n",
    "# Create a loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_gpu.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "  train_loss = 0\n",
    "  model_gpu.train()\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    # Put data on target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model_gpu(X)\n",
    "    # print(type(y_pred), y_pred)\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust train loss to number of batches\n",
    "  train_loss /= len(train_dataloader)\n",
    "\n",
    "  ### Testing loop\n",
    "  test_loss_total = 0\n",
    "  \n",
    "  # Put model in eval mode and turn on inference mode\n",
    "  model_gpu.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "      # Make sure test data on target device\n",
    "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "      test_pred = model_gpu(X_test)\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "      test_loss_total += test_loss.item()\n",
    "\n",
    "    # Adjust test loss total for number of batches\n",
    "    test_loss_total /= len(test_dataloader)\n",
    "\n",
    "  # Print out what's happening\n",
    "  print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")\n",
    "\n",
    "  # Save model weights after each epoch\n",
    "  save_path = os.path.join(model_weights_path, f\"model_epoch_{epoch}.pth\")\n",
    "  os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "  torch.save(model_gpu.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1CsHhPpxp1w"
   },
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1690805570725,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "iVyM5cC6yBkF",
    "outputId": "d6311b6e-b081-41dd-bc92-080b5f439c47",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.672596600Z",
     "start_time": "2023-08-03T12:50:03.530675500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x16ed220ca90>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions with the trained model\n",
    "plt.imshow(test_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1690805570725,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "NGide8hMWP17",
    "outputId": "be7490a9-d239-426b-c2de-0e48f185ab3b",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.690581100Z",
     "start_time": "2023-08-03T12:50:03.673595700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([7])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logits -> Prediction probabilities -> Prediction labels\n",
    "old_model_pred_logits = model_gpu(test_data[0][0].unsqueeze(dim=0).to(device)) # make sure image is right shape + on right device\n",
    "old_model_pred_probs = torch.softmax(old_model_pred_logits, dim=1)\n",
    "old_model_pred_label = torch.argmax(old_model_pred_probs, dim=1)\n",
    "old_model_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1690805570725,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "jNCPUtO_Wuj5",
    "outputId": "558df7c7-3c11-4ada-c37c-49857d9f133f",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.749077700Z",
     "start_time": "2023-08-03T12:50:03.691095900Z"
    }
   },
   "outputs": [],
   "source": [
    "num_to_plot = 5\n",
    "\n",
    "for i in range(num_to_plot):\n",
    "  # Get image and labels from the test data\n",
    "  img = test_data[i][0]\n",
    "  label = test_data[i][1]\n",
    "\n",
    "  # Make prediction on image\n",
    "  old_model_pred_logits = model_gpu(img.unsqueeze(dim=0).to(device))\n",
    "  old_model_pred_probs = torch.softmax(old_model_pred_logits, dim=1)\n",
    "  old_model_pred_label = torch.argmax(old_model_pred_probs, dim=1)\n",
    "# \n",
    "#   # Plot the image and prediction\n",
    "#   plt.figure()\n",
    "#   plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "#   plt.title(f\"Truth: {label} | Pred: {model_pred_label.cpu().item()}\")\n",
    "#   plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11. Generate sample dataset and its weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2639,
     "status": "ok",
     "timestamp": 1690805883800,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "a_ELulZFo9_p",
    "outputId": "2b688f21-6e61-443f-a0b2-2c4b9550535e",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.749077700Z",
     "start_time": "2023-08-03T12:50:03.705859100Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# drive_path = \"/content/drive/My Drive/Colab Notebooks/mnist\"\n",
    "# drive_path = r\"D:\\GitHub\\transition-matrix-ml\\notebooks\"\n",
    "drive_path = \"C:/Courses/transition-matrix-ml/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1690805892873,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "ibLxia7Qo5t-",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.755570700Z",
     "start_time": "2023-08-03T12:50:03.723115200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sample_dataset(input_dataset):\n",
    "    \"\"\"\n",
    "    This function creates a new dataset subset with the\n",
    "    specified number of samples.\n",
    "    :param input_dataset: Original training dataset\n",
    "    :return: Subset of the training dataset\n",
    "            and a list of unique IDs (indices from the original dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    n_samples = 1000\n",
    "\n",
    "    generate_sample_labels = input_dataset.targets.numpy()\n",
    "\n",
    "    # Determine the proportion of each class in the training dataset\n",
    "    _, counts = np.unique(generate_sample_labels, return_counts=True)\n",
    "    proportions = counts / len(generate_sample_labels)\n",
    "\n",
    "    # Determine the number of samples to extract for each class\n",
    "    samples_per_class = (proportions * n_samples).astype(int)\n",
    "\n",
    "    # Adjust samples for any rounding issues to ensure exactly 1000 samples\n",
    "    while np.sum(samples_per_class) < n_samples:\n",
    "        class_with_max_samples = np.argmax(proportions)\n",
    "        samples_per_class[class_with_max_samples] += 1\n",
    "    \n",
    "    # Extract samples based on the proportions\n",
    "    indices_to_extract = []\n",
    "\n",
    "    for gs_label, n_samples in enumerate(samples_per_class):\n",
    "        label_indices = np.where(generate_sample_labels == gs_label)[0]\n",
    "        chosen_indices = np.random.choice(label_indices, n_samples, replace=False)\n",
    "        indices_to_extract.extend(chosen_indices)\n",
    "\n",
    "    # Shuffle the indices for randomness\n",
    "    np.random.shuffle(indices_to_extract)\n",
    "\n",
    "    # Return a subset of the dataset\n",
    "    sample_dataset = torch.utils.data.Subset(train_data, indices_to_extract)\n",
    "\n",
    "    return sample_dataset, indices_to_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1690805898732,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "2hIelW6nvehF",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.758562600Z",
     "start_time": "2023-08-03T12:50:03.736588400Z"
    }
   },
   "outputs": [],
   "source": [
    "my_sample_dataset_train, my_indices_train = generate_sample_dataset(train_data)\n",
    "my_sample_dataset_test, my_indices_test = generate_sample_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataset.Subset at 0x16ed207ce20>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sample_dataset_train\n",
    "my_sample_dataset_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.773684400Z",
     "start_time": "2023-08-03T12:50:03.751575500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'model = MNISTModel(input_shape=1, hidden_units=10, output_shape=10).to(device)\\n\\nmodel_weights_path = \"../model_weights/\"\\n\\nmodel.load_state_dict(torch.load(os.path.join(model_weights_path, \\n                                              f\"model_epoch_{n_epochs}.pth\")))  # Load your trained weights\\nmodel.eval()  # Set the model to evaluation mode\\n\\nflattened_outputs = []\\n\\nwith torch.inference_mode():\\n    for batch, (X_sample, _) in enumerate(my_sample_dataset_train):  # we don\\'t need labels for prediction\\n        X_sample = X_sample.to(device)\\n        preds, flattened = model(X_sample.unsqueeze(dim=0).to(device), return_flattened=True)\\n        flattened_outputs.append(flattened)\\n\\n        # At this point, `flattened_outputs` is a list of tensors, \\n        # where each tensor corresponds to the flattened outputs for a batch of data.\\n\\n    all_flattened_outputs  = torch.cat(flattened_outputs, dim=0)  # Concatenate all activations'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = MNISTModel(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "\n",
    "model_weights_path = \"../model_weights/\"\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(model_weights_path, \n",
    "                                              f\"model_epoch_{n_epochs}.pth\")))  # Load your trained weights\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "flattened_outputs = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch, (X_sample, _) in enumerate(my_sample_dataset_train):  # we don't need labels for prediction\n",
    "        X_sample = X_sample.to(device)\n",
    "        preds, flattened = model(X_sample.unsqueeze(dim=0).to(device), return_flattened=True)\n",
    "        flattened_outputs.append(flattened)\n",
    "\n",
    "        # At this point, `flattened_outputs` is a list of tensors, \n",
    "        # where each tensor corresponds to the flattened outputs for a batch of data.\n",
    "\n",
    "    all_flattened_outputs  = torch.cat(flattened_outputs, dim=0)  # Concatenate all activations'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.826656400Z",
     "start_time": "2023-08-03T12:50:03.769175600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1690805906678,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "czewqwIJmIQd",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.839144Z",
     "start_time": "2023-08-03T12:50:03.789162100Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_prediction_weights(input_dataset, input_weights_path):\n",
    "    \"\"\"\n",
    "    This function extracts the weights from the model in the prediction stage\n",
    "    :param input_dataset:\n",
    "    :param input_weights_path: \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    total_images = len(input_dataset)\n",
    "\n",
    "    my_true_labels = []\n",
    "    my_pred_flattened = []\n",
    "    my_pred_logits = []\n",
    "    my_pred_labels = []\n",
    "\n",
    "    sample_model = MNISTModel(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "\n",
    "    sample_model.load_state_dict(torch.load(os.path.join(input_weights_path,\n",
    "                                                  f\"model_epoch_{n_epochs}.pth\")))  # Load your trained weights\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for sample_batch, (x_sample, y_sample) in tqdm(enumerate(input_dataset)):\n",
    "            x_sample = x_sample.to(device)\n",
    "            preds, flattened = sample_model(x_sample.unsqueeze(dim=0).to(device), return_flattened=True)\n",
    "            \n",
    "            # Save the true labels for each image\n",
    "            my_true_labels.append(y_sample)\n",
    "\n",
    "            # Save the activations after the nn.Flatten() layer for each image\n",
    "            my_pred_flattened.append(flattened)\n",
    "            \n",
    "            # Save the prediction logits\n",
    "            my_pred_logits.append(preds)\n",
    "\n",
    "            # Save the prediction labels\n",
    "            model_pred_labels = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
    "            my_pred_labels.append(model_pred_labels)\n",
    "            \n",
    "            # At this point, `flattened_outputs` is a list of tensors, \n",
    "            # where each tensor corresponds to the flattened outputs for a batch of data.\n",
    "\n",
    "        my_pred_flattened  = torch.cat(my_pred_flattened, dim=0).cpu()  # Concatenate all activations\n",
    "        my_pred_logits = torch.cat(my_pred_logits).cpu()\n",
    "        my_pred_labels = torch.cat(my_pred_labels).cpu()\n",
    "\n",
    "    return my_pred_flattened, my_pred_logits, my_pred_labels, my_true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'def generate_prediction_weights(input_dataset, input_weights_path):\\n    \"\"\"\\n    This function extracts the weights from the model in the prediction stage\\n    :param input_weights_path: \\n    :param input_dataset:\\n    :return:\\n    \"\"\"\\n    total_images = len(input_dataset)\\n\\n    my_label_true = []\\n    my_pred_flattened = []\\n    my_pred_logits = []\\n    my_label_preds = []\\n\\n    sample_model = MNISTModel(input_shape=1, hidden_units=10, output_shape=10).to(device)\\n\\n    sample_model.load_state_dict(torch.load(os.path.join(input_weights_path,\\n                                                         f\"model_epoch_{n_epochs}.pth\")))  # Load your trained weights\\n    model.eval()  # Set the model to evaluation mode\\n\\n    # flattened_outputs = []\\n\\n    with torch.inference_mode():\\n        for batch, (x_sample, y_sample) in enumerate(my_sample_dataset_train):  # we don\\'t need labels for prediction\\n            x_sample = x_sample.to(device)\\n            preds, flattened = sample_model(x_sample.unsqueeze(dim=0).to(device), return_flattened=True)\\n\\n            # Save the true labels for each image\\n            my_label_true.append(y_sample)\\n\\n            # Save the activations after the nn.Flatten() layer for each image\\n            my_pred_flattened.append(flattened)\\n\\n            # Save the prediction logits\\n            my_pred_logits.append(preds)\\n\\n            # Save the prediction labels\\n            model_pred_labels = torch.argmax(torch.softmax(preds, dim=1), dim=1)\\n            my_label_preds.append(model_pred_labels)\\n\\n            # At this point, `flattened_outputs` is a list of tensors, \\n            # where each tensor corresponds to the flattened outputs for a batch of data.\\n\\n        my_pred_flattened  = torch.cat(my_pred_flattened, dim=0).cpu()  # Concatenate all activations\\n        my_pred_logits = torch.cat(my_pred_logits).cpu()\\n        my_label_preds = torch.cat(my_label_preds).cpu()\\n\\n    for item in range(total_images):\\n        # Get image and labels from the test data\\n        input_image = input_dataset[item][0]\\n        input_label = input_dataset[item][1]\\n        my_label_true.append(input_label)\\n\\n        # Extract and save the weights after the nn.Flatten() layer\\n        model_pred_flattened = model.get_flatten\\n        # model_pred_flattened = model(input_image.unsqueeze(dim=0).get_flatten.to(device))\\n        my_pred_flattened.append(model_pred_flattened)\\n        print(f\"The flattened weights:\\n {my_pred_flattened}\")\\n        # print(f\"The shape of the tensor:\\n {my_pred_flattened.shape}\")\\n\\n        # Save the prediction weights\\n        model_pred_logits = model_gpu(input_image.unsqueeze(dim=0).to(device))\\n        my_pred_logits.append(model_pred_logits)\\n\\n        # Save the prediction labels\\n        model_pred_labels = torch.argmax(torch.softmax(model_pred_logits, dim=1), dim=1)\\n        my_label_preds.append(model_pred_labels)\\n\\n    my_pred_flattened = torch.cat(my_pred_flattened).cpu()\\n    my_pred_logits = torch.cat(my_pred_logits).cpu()\\n    my_label_preds = torch.cat(my_label_preds).cpu()\\n\\n    return my_pred_flattened, my_pred_logits, my_label_preds, my_label_true\\n'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def generate_prediction_weights(input_dataset, input_weights_path):\n",
    "    \"\"\"\n",
    "    This function extracts the weights from the model in the prediction stage\n",
    "    :param input_weights_path: \n",
    "    :param input_dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    total_images = len(input_dataset)\n",
    "\n",
    "    my_label_true = []\n",
    "    my_pred_flattened = []\n",
    "    my_pred_logits = []\n",
    "    my_label_preds = []\n",
    "\n",
    "    sample_model = MNISTModel(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "\n",
    "    sample_model.load_state_dict(torch.load(os.path.join(input_weights_path,\n",
    "                                                         f\"model_epoch_{n_epochs}.pth\")))  # Load your trained weights\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # flattened_outputs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (x_sample, y_sample) in enumerate(my_sample_dataset_train):  # we don't need labels for prediction\n",
    "            x_sample = x_sample.to(device)\n",
    "            preds, flattened = sample_model(x_sample.unsqueeze(dim=0).to(device), return_flattened=True)\n",
    "\n",
    "            # Save the true labels for each image\n",
    "            my_label_true.append(y_sample)\n",
    "\n",
    "            # Save the activations after the nn.Flatten() layer for each image\n",
    "            my_pred_flattened.append(flattened)\n",
    "\n",
    "            # Save the prediction logits\n",
    "            my_pred_logits.append(preds)\n",
    "\n",
    "            # Save the prediction labels\n",
    "            model_pred_labels = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
    "            my_label_preds.append(model_pred_labels)\n",
    "\n",
    "            # At this point, `flattened_outputs` is a list of tensors, \n",
    "            # where each tensor corresponds to the flattened outputs for a batch of data.\n",
    "\n",
    "        my_pred_flattened  = torch.cat(my_pred_flattened, dim=0).cpu()  # Concatenate all activations\n",
    "        my_pred_logits = torch.cat(my_pred_logits).cpu()\n",
    "        my_label_preds = torch.cat(my_label_preds).cpu()\n",
    "\n",
    "    for item in range(total_images):\n",
    "        # Get image and labels from the test data\n",
    "        input_image = input_dataset[item][0]\n",
    "        input_label = input_dataset[item][1]\n",
    "        my_label_true.append(input_label)\n",
    "\n",
    "        # Extract and save the weights after the nn.Flatten() layer\n",
    "        model_pred_flattened = model.get_flatten\n",
    "        # model_pred_flattened = model(input_image.unsqueeze(dim=0).get_flatten.to(device))\n",
    "        my_pred_flattened.append(model_pred_flattened)\n",
    "        print(f\"The flattened weights:\\n {my_pred_flattened}\")\n",
    "        # print(f\"The shape of the tensor:\\n {my_pred_flattened.shape}\")\n",
    "\n",
    "        # Save the prediction weights\n",
    "        model_pred_logits = model_gpu(input_image.unsqueeze(dim=0).to(device))\n",
    "        my_pred_logits.append(model_pred_logits)\n",
    "\n",
    "        # Save the prediction labels\n",
    "        model_pred_labels = torch.argmax(torch.softmax(model_pred_logits, dim=1), dim=1)\n",
    "        my_label_preds.append(model_pred_labels)\n",
    "\n",
    "    my_pred_flattened = torch.cat(my_pred_flattened).cpu()\n",
    "    my_pred_logits = torch.cat(my_pred_logits).cpu()\n",
    "    my_label_preds = torch.cat(my_label_preds).cpu()\n",
    "\n",
    "    return my_pred_flattened, my_pred_logits, my_label_preds, my_label_true\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:03.840141400Z",
     "start_time": "2023-08-03T12:50:03.800170Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1690805913891,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "BcfdHv_pmIQd",
    "outputId": "6dbadf74-1445-4830-8724-c095be2ef938",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:04.656174400Z",
     "start_time": "2023-08-03T12:50:03.814182200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2488.02it/s]\n",
      "1000it [00:00, 2435.49it/s]\n"
     ]
    }
   ],
   "source": [
    "my_prediction_weights_train = generate_prediction_weights(my_sample_dataset_train, model_weights_path)\n",
    "\n",
    "my_prediction_weights_test = generate_prediction_weights(my_sample_dataset_test, model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:04.701104300Z",
     "start_time": "2023-08-03T12:50:04.657171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 490])\n",
      "torch.Size([1000, 490])\n"
     ]
    }
   ],
   "source": [
    "print(my_prediction_weights_train[0].shape)\n",
    "print(my_prediction_weights_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "n_pixels = 784\n",
    "\n",
    "def tensor_to_dataframe(tensor):\n",
    "    \"\"\"Convert a PyTorch tensor to a pandas DataFrame.\"\"\"\n",
    "    return pd.DataFrame(tensor.cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:04.921948300Z",
     "start_time": "2023-08-03T12:50:04.673155700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Train data\n",
    "# Save the images and labels to a CSV file\n",
    "with open(f\"{drive_path}/mnist_matrix_B_train.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Header\n",
    "    header = [\"unique_id\", \"label\"] + [\"pixel\" + str(i) for i in range(n_pixels)]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Rows\n",
    "    for sample_idx, (sample_image, sample_label) in zip(my_indices_train, my_sample_dataset_train):\n",
    "        sample_image = sample_image[0].numpy().flatten()  # Extract the tensor from the tuple\n",
    "        row = [sample_idx, sample_label] + sample_image.tolist()\n",
    "        csv_writer.writerow(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:05.263372500Z",
     "start_time": "2023-08-03T12:50:04.923942900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1767,
     "status": "ok",
     "timestamp": 1690805920756,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "SMYLfeE3mIQd",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:05.511030500Z",
     "start_time": "2023-08-03T12:50:05.271906900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the tensor to a DataFrame\n",
    "df_flattened_train = tensor_to_dataframe(my_prediction_weights_train[0])\n",
    "df_logits_train = tensor_to_dataframe(my_prediction_weights_train[1])\n",
    "df_preds_train = tensor_to_dataframe(my_prediction_weights_train[2])\n",
    "df_labels_train = pd.DataFrame(my_prediction_weights_train[3])\n",
    "\n",
    "# Convert indices to a DataFrame\n",
    "df_indices_train = pd.DataFrame(my_indices_train, columns=[\"unique_id\"])\n",
    "\n",
    "# Concatenate indices with other DataFrames\n",
    "df_flattened_train = pd.concat([df_indices_train, df_flattened_train], axis=1)\n",
    "df_logits_train = pd.concat([df_indices_train, df_logits_train], axis=1)\n",
    "df_preds_train = pd.concat([df_indices_train, df_preds_train], axis=1)\n",
    "df_labels_train = pd.concat([df_indices_train, df_labels_train], axis=1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "with open(f\"{drive_path}/mnist_matrix_A_train.csv\", \"w\", newline=\"\") as file_flattened:\n",
    "    df_flattened_train.to_csv(file_flattened)\n",
    "with open(f\"{drive_path}/mnist_logits_train.csv\", \"w\", newline=\"\") as file_logits:\n",
    "    df_logits_train.to_csv(file_logits)\n",
    "with open(f\"{drive_path}/mnist_pred_labels_train.csv\", \"w\", newline=\"\") as file_preds:\n",
    "    df_preds_train.to_csv(file_preds)\n",
    "with open(f\"{drive_path}/mnist_true_labels_train.csv\", \"w\", newline=\"\") as file_labels:\n",
    "    df_labels_train.to_csv(file_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Test data\n",
    "# Save the images and labels to a CSV file\n",
    "with open(f\"{drive_path}/mnist_matrix_B_test.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Header\n",
    "    header = [\"unique_id\", \"label\"] + [\"pixel\" + str(i) for i in range(n_pixels)]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Rows\n",
    "    for sample_idx, (sample_image, sample_label) in zip(my_indices_test, my_sample_dataset_test):\n",
    "        sample_image = sample_image[0].numpy().flatten()  # Extract the tensor from the tuple\n",
    "        row = [sample_idx, sample_label] + sample_image.tolist()\n",
    "        csv_writer.writerow(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:05.854118700Z",
     "start_time": "2023-08-03T12:50:05.514023300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Convert the tensor to a DataFrame\n",
    "df_flattened_test = tensor_to_dataframe(my_prediction_weights_test[0])\n",
    "df_logits_test = tensor_to_dataframe(my_prediction_weights_test[1])\n",
    "df_preds_test = tensor_to_dataframe(my_prediction_weights_test[2])\n",
    "df_labels_test = pd.DataFrame(my_prediction_weights_test[3])\n",
    "\n",
    "# Convert indices to a DataFrame\n",
    "df_indices_test = pd.DataFrame(my_indices_test, columns=[\"unique_id\"])\n",
    "\n",
    "# Concatenate indices with other DataFrames\n",
    "df_flattened_test = pd.concat([df_indices_test, df_flattened_test], axis=1)\n",
    "df_logits_test = pd.concat([df_indices_test, df_logits_test], axis=1)\n",
    "df_preds_test = pd.concat([df_indices_test, df_preds_test], axis=1)\n",
    "df_labels_test = pd.concat([df_indices_test, df_labels_test], axis=1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "with open(f\"{drive_path}/mnist_matrix_A_test.csv\", \"w\", newline=\"\") as file_flattened:\n",
    "    df_flattened_test.to_csv(file_flattened)\n",
    "with open(f\"{drive_path}/mnist_logits_test.csv\", \"w\", newline=\"\") as file_logits:\n",
    "    df_logits_test.to_csv(file_logits)\n",
    "with open(f\"{drive_path}/mnist_pred_labels_test.csv\", \"w\", newline=\"\") as file_preds:\n",
    "    df_preds_test.to_csv(file_preds)\n",
    "with open(f\"{drive_path}/mnist_true_labels_test.csv\", \"w\", newline=\"\") as file_labels:\n",
    "    df_labels_test.to_csv(file_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:06.099597400Z",
     "start_time": "2023-08-03T12:50:05.861634900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQwzqlBWxrpG"
   },
   "source": [
    "## 12. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6082,
     "status": "ok",
     "timestamp": 1690805934993,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "CTIlKRqqYF02",
    "outputId": "fe9d072c-a760-4d07-9682-b73a22e07f57",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:06.115112200Z",
     "start_time": "2023-08-03T12:50:06.101131600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'# See if torchmetrics exists, if not, install it\\ntry:\\n    import torchmetrics, mldxtend\\n    print(f\"mlxtend version: {mlxtend.__version__}\")\\n    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19.0 or higher\"\\nexcept:\\n    !pip install -q torchmetrics -U mlxtend # <- Note: If you\\'re using Google Colab, this may require restarting the runtime\\n    import torchmetrics, mlxtend\\n    print(f\"mlxtend version: {mlxtend.__version__}\")'"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# See if torchmetrics exists, if not, install it\n",
    "try:\n",
    "    import torchmetrics, mldxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19.0 or higher\"\n",
    "except:\n",
    "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690805934993,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "SqYUDscuYGSd",
    "outputId": "051c47e0-1d7c-41e3-b8e8-b5e6602da52f",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:06.176648400Z",
     "start_time": "2023-08-03T12:50:06.116109600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.0\n"
     ]
    }
   ],
   "source": [
    "# Import mlxtend upgraded version\n",
    "import mlxtend\n",
    "print(mlxtend.__version__)\n",
    "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be versioned 0.19.0 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "75a9f356c1574bf3ab38e73d0144b344",
      "c12b0b3950df471bb5b822f1afce9046",
      "acb8fdb3932945d4b07232dee71fface",
      "568a368e8b094ec19c16f92281859c1c",
      "182de626138f4fc5abec16510f997cf9",
      "1312213efa0348c8b426c32fd115fa5c",
      "3bd67740fd3d41e9bbd6112e3417cc58",
      "f22ac599ac61405fb3fac039379f03f0",
      "076e6e7c43b74724a94383ee353dc0a1",
      "c22f6b739ca5473e8e612277dc267fa0",
      "2edb0a13541a4dc79354be2ea3c6916f"
     ]
    },
    "executionInfo": {
     "elapsed": 3598,
     "status": "ok",
     "timestamp": 1690805938586,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "8kJO6BqAyBEc",
    "outputId": "798eb44c-8729-417e-9b3e-d0b3ceda16cd",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:07.571612700Z",
     "start_time": "2023-08-03T12:50:06.134124300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:01, 439.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions across all test data\n",
    "from tqdm.auto import tqdm\n",
    "model_gpu.eval()\n",
    "y_preds = []\n",
    "with torch.inference_mode():\n",
    "    for batch, (X, y) in tqdm(enumerate(test_dataloader)):\n",
    "        # Make sure data on right device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Forward pass\n",
    "        y_pred_logits = model_gpu(X)\n",
    "        # Logits -> Pred probs -> Pred label\n",
    "        y_pred_labels = torch.argmax(torch.softmax(y_pred_logits, dim=1), dim=1)\n",
    "        # Append the labels to the preds list\n",
    "        y_preds.append(y_pred_labels)\n",
    "    y_preds = torch.cat(y_preds).cpu()\n",
    "len(y_preds)\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690805938586,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "HMs7XPLTZBV4",
    "outputId": "fb270694-bcfd-44b8-d13a-638c9bdf09c3",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:07.616532600Z",
     "start_time": "2023-08-03T12:50:07.573017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]),\n tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.targets[:10], y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1690805939399,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     },
     "user_tz": -180
    },
    "id": "7lK_v2JyZOOG",
    "outputId": "021e9936-a16f-4485-e9cf-40357d039611",
    "ExecuteTime": {
     "end_time": "2023-08-03T12:50:08.707348400Z",
     "start_time": "2023-08-03T12:50:07.589487200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# Setup confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_preds,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fix, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj6bDhoWxt2y"
   },
   "source": [
    "## 13. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7NdlYAKmIQf"
   },
   "source": [
    "random_tensor = torch.rand([1, 3, 64, 64])\n",
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzJLP6XqmIQf"
   },
   "source": [
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=64,\n",
    "                       kernel_size=3,\n",
    "                       stride=2,\n",
    "                       padding=1)\n",
    "\n",
    "print(f\"Random tensor original shape: {random_tensor.shape}\")\n",
    "random_tensor_through_conv_layer = conv_layer(random_tensor)\n",
    "print(f\"Random tensor through conv layer shape: {random_tensor_through_conv_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHS20cNTxwSi"
   },
   "source": [
    "## 14. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
    "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
    "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
    "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VgZt5POmIQf"
   },
   "source": [
    "# Download FashionMNIST train & test\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "fashion_mnist_train = datasets.FashionMNIST(root=\".\",\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "fashion_mnist_test = datasets.FashionMNIST(root=\".\",\n",
    "                                           train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "len(fashion_mnist_train), len(fashion_mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wctAWxjmIQg"
   },
   "source": [
    "# Get the class names of the Fashion MNIST dataset\n",
    "fashion_mnist_class_names = fashion_mnist_train.classes\n",
    "fashion_mnist_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReIeE__tmIQh"
   },
   "source": [
    "# Turn FashionMNIST datasets into dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "fashion_mnist_train_dataloader = DataLoader(fashion_mnist_train,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True)\n",
    "\n",
    "fashion_mnist_test_dataloader = DataLoader(fashion_mnist_test,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=False)\n",
    "\n",
    "len(fashion_mnist_train_dataloader), len(fashion_mnist_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AteaZRpxmIQh"
   },
   "source": [
    "# model_2 is the same architecture as MNISTModel\n",
    "model_2 = MNISTModel(input_shape=1,\n",
    "                      hidden_units=10,\n",
    "                      output_shape=10).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBvSxHM-mIQi"
   },
   "source": [
    "# Setup loss and optimizer\n",
    "from torch import nn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup metrics\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "acc_fn = Accuracy(task=\"multiclass\", num_classes=len(fashion_mnist_class_names)).to(device)\n",
    "\n",
    "# Setup training/testing loop\n",
    "epochs = 2\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  train_loss, test_loss_total = 0, 0\n",
    "  train_acc, test_acc = 0, 0\n",
    "\n",
    "  ### Training\n",
    "  model_2.train()\n",
    "  for batch, (X_train, y_train) in enumerate(fashion_mnist_train_dataloader):\n",
    "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "    # Forward pass and loss\n",
    "    y_pred = model_2(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    train_loss += loss\n",
    "    train_acc += acc_fn(y_pred, y_train)\n",
    "\n",
    "    # Backprop and gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust the loss/acc (find the loss/acc per epoch)\n",
    "  train_loss /= len(fashion_mnist_train_dataloader)\n",
    "  train_acc /= len(fashion_mnist_train_dataloader)\n",
    "\n",
    "  ### Testing\n",
    "  model_2.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(fashion_mnist_test_dataloader):\n",
    "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "      # Forward pass and loss\n",
    "      y_pred_test = model_2(X_test)\n",
    "      test_loss = loss_fn(y_pred_test, y_test)\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "      test_acc += acc_fn(y_pred_test, y_test)\n",
    "  \n",
    "    # Adjust the loss/acc (find the loss/acc per epoch)\n",
    "    test_loss /= len(fashion_mnist_test_dataloader)\n",
    "    test_acc /= len(fashion_mnist_test_dataloader)\n",
    "    \n",
    "  # Print out what's happening\n",
    "  print(f\"Epoch: {epoch} | Train loss: {train_loss:.3f} | Train acc: {train_acc:.2f} | Test loss: {test_loss_total:.3f} | Test acc: {test_acc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ysX-JSKmIQi"
   },
   "source": [
    "# Make predictions with trained model_2\n",
    "test_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "  for X_test, y_test in tqdm(fashion_mnist_test_dataloader):\n",
    "    y_logits = model_2(X_test.to(device))\n",
    "    y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "    y_pred_labels = torch.argmax(y_pred_probs, dim=1)\n",
    "    test_preds.append(y_pred_labels)\n",
    "test_preds = torch.cat(test_preds).cpu() # matplotlib likes CPU\n",
    "test_preds[:10], len(test_preds)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amjDUjkSmIQi"
   },
   "source": [
    "# Get wrong prediction indexes\n",
    "import numpy as np\n",
    "wrong_pred_indexes = np.where(test_preds != fashion_mnist_test.targets)[0]\n",
    "len(wrong_pred_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TXBJdZ3mIQi"
   },
   "source": [
    "# Select random 9 wrong predictions and plot them\n",
    "import random\n",
    "random_selection = random.sample(list(wrong_pred_indexes), k=9)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, idx in enumerate(random_selection):\n",
    "  # Get true and pred labels\n",
    "  true_label = fashion_mnist_class_names[fashion_mnist_test[idx][1]]\n",
    "  pred_label = fashion_mnist_class_names[test_preds[idx]]\n",
    "\n",
    "  # Plot the wrong prediction with its original label\n",
    "  plt.subplot(3, 3, i+1)\n",
    "  plt.imshow(fashion_mnist_test[idx][0].squeeze(), cmap=\"gray\")\n",
    "  plt.title(f\"True: {true_label} | Pred: {pred_label}\", c=\"r\")\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoDfh-fKXtyU"
   },
   "source": [
    "From the look of some of these predictions, the model is getting about as confused as I would...\n",
    "\n",
    "For example it predicts \"Sneaker\" instead of \"Sandal\" when it could have easily been a \"Sneaker\".\n",
    "\n",
    "The same goes for the confusion between the classes of \"T-shirt/top\" and \"Shirt\", many of the examples here look similar."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04ed2a1850624ea3a724daf1f82c5383": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "076e6e7c43b74724a94383ee353dc0a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11b3193c755d4b91becf14efa1c443f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1312213efa0348c8b426c32fd115fa5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "182de626138f4fc5abec16510f997cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2239f77486f348f989463de8eee7fbe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96f1ccc77d3641718bf41245e0c1c8c1",
      "placeholder": "​",
      "style": "IPY_MODEL_fac90735353a4755935a42a125a72a73",
      "value": "100%"
     }
    },
    "2691f9aec2614a1298133154a552dc71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2edb0a13541a4dc79354be2ea3c6916f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bd67740fd3d41e9bbd6112e3417cc58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "540f82a2be3d4f629c6a6f0b2713fa07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568a368e8b094ec19c16f92281859c1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c22f6b739ca5473e8e612277dc267fa0",
      "placeholder": "​",
      "style": "IPY_MODEL_2edb0a13541a4dc79354be2ea3c6916f",
      "value": " 625/? [00:03&lt;00:00, 216.07it/s]"
     }
    },
    "635e558c36e8415cafe69e315c70d1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2691f9aec2614a1298133154a552dc71",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11b3193c755d4b91becf14efa1c443f0",
      "value": 2
     }
    },
    "75a9f356c1574bf3ab38e73d0144b344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12b0b3950df471bb5b822f1afce9046",
       "IPY_MODEL_acb8fdb3932945d4b07232dee71fface",
       "IPY_MODEL_568a368e8b094ec19c16f92281859c1c"
      ],
      "layout": "IPY_MODEL_182de626138f4fc5abec16510f997cf9"
     }
    },
    "96f1ccc77d3641718bf41245e0c1c8c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb8fdb3932945d4b07232dee71fface": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f22ac599ac61405fb3fac039379f03f0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_076e6e7c43b74724a94383ee353dc0a1",
      "value": 1
     }
    },
    "b2be661e7414444eafefc50786dd9b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2239f77486f348f989463de8eee7fbe9",
       "IPY_MODEL_635e558c36e8415cafe69e315c70d1dd",
       "IPY_MODEL_d73b703d06ee496781d48080e82edcd7"
      ],
      "layout": "IPY_MODEL_04ed2a1850624ea3a724daf1f82c5383"
     }
    },
    "b89e38295f934a4785756a4741ab1055": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c12b0b3950df471bb5b822f1afce9046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1312213efa0348c8b426c32fd115fa5c",
      "placeholder": "​",
      "style": "IPY_MODEL_3bd67740fd3d41e9bbd6112e3417cc58",
      "value": ""
     }
    },
    "c22f6b739ca5473e8e612277dc267fa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73b703d06ee496781d48080e82edcd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_540f82a2be3d4f629c6a6f0b2713fa07",
      "placeholder": "​",
      "style": "IPY_MODEL_b89e38295f934a4785756a4741ab1055",
      "value": " 2/2 [00:54&lt;00:00, 26.93s/it]"
     }
    },
    "f22ac599ac61405fb3fac039379f03f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "fac90735353a4755935a42a125a72a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
