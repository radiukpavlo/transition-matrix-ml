{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# %config InlineBackend.figure_format = 'svg' \n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43affeab9da11131"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE_PATH = '.\\projects_temp-figs'\n",
    "\n",
    "# Generate a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# The y_test and y_pred can be used to test the plot_roc_and_calculate_auc function\n",
    "(y_test, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8fd755b4d4dd1ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_plot_roc_binary(y_true, y_scores, save_path, figure_name):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve and calculates the \n",
    "    Area Under the Curve (AUC) for a binary classifier.\n",
    "    \n",
    "    The function takes two arguments: `y_true`, an array of true binary labels, \n",
    "    and `y_scores`, an array of predicted scores/probabilities from the classifier. \n",
    "    It calculates the True Positive Rate (TPR) and False Positive Rate (FPR) at \n",
    "    various threshold settings derived from the predicted scores. The ROC curve \n",
    "    is then plotted with TPR against FPR, and the AUC is calculated using the \n",
    "    trapezoidal rule.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array-like): True binary labels. Must be the same length as `y_scores`.\n",
    "    y_scores (array-like): Predicted scores/probabilities for the positive class.\n",
    "    \n",
    "    Returns:\n",
    "    float: The AUC (Area Under Curve) value, a measure of the classifier's performance.\n",
    "    \n",
    "    Note:\n",
    "    This function assumes that the positive class is labeled as '1' and the negative\n",
    "    class as '0'. The `y_scores` array should contain probabilities or scores that \n",
    "    reflect the likelihood of belonging to the positive class.\n",
    "    \"\"\"\n",
    "    # Define the figure name and path\n",
    "    my_save_path = os.path.join(save_path, figure_name)\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Sort scores and corresponding true values\n",
    "    desc_score_indices = np.argsort(y_scores)[::-1]\n",
    "    y_scores = y_scores[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "\n",
    "    # Temporarily ignore divide by zero warnings\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    # Compute True Positive and False Positive Counts\n",
    "    tp = np.cumsum(y_true)  # Cumulative sum of true positives\n",
    "    fp = np.cumsum(1 - y_true)  # Cumulative sum of false positives\n",
    "    tn = fp[-1] - fp  # True negatives at each threshold\n",
    "    fn = tp[-1] - tp  # False negatives at each threshold\n",
    "\n",
    "    # Calculate TPR and FPR\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Replace NaNs in FPR with zero\n",
    "    fpr = np.nan_to_num(fpr)\n",
    "    tpr = np.nan_to_num(tpr)\n",
    "\n",
    "    # Restore the default error handling for NumPy\n",
    "    np.seterr(divide='warn', invalid='warn')\n",
    "    \n",
    "    # Calculate AUC using the trapezoidal rule\n",
    "    roc_auc = np.trapz(tpr, fpr)\n",
    "\n",
    "    # Plotting ROC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='darkgray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "    plt.savefig(my_save_path, format='png', bbox_inches='tight')\n",
    "    print(f\"Plot saved to {save_path} as {figure_name}\")\n",
    "    # plt.gcf().set_dpi(200)\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b51512639eac3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_auc = my_plot_roc_binary(y_test, y_pred, SAVE_PATH, figure_name='my_plot_roc_binary.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43872dc41edaf6f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_auc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d946c0456ae41db0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_roc_skl_binary(y_true, y_scores, save_path, figure_name):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve and calculates the\n",
    "    Area Under the Curve (AUC) for a binary classifier using sklearn's roc_curve \n",
    "    and roc_auc_score functions.\n",
    "    \n",
    "    This function is designed to work with binary classification models. It takes\n",
    "    two arguments: `y_true`, an array of true binary labels, and `y_scores`, an \n",
    "    array of predicted probabilities or decision function scores from the classifier. \n",
    "    It utilizes sklearn's roc_curve to calculate the True Positive Rate (TPR) and \n",
    "    False Positive Rate (FPR) at various thresholds, and plots these to produce the ROC curve.\n",
    "    The AUC is calculated using sklearn's roc_auc_score.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array-like): True binary labels. Must be the same length as `y_scores`.\n",
    "    y_scores (array-like): Predicted probabilities or decision function scores for\n",
    "                           the positive class. Must be a 1D array.\n",
    "    \n",
    "    Returns:\n",
    "    float: The AUC (Area Under Curve) value, indicating the performance of the classifier.\n",
    "    \n",
    "    Note:\n",
    "    The function assumes a binary classification task where the positive class is labeled as '1'\n",
    "    and the negative class as '0'. The `y_scores` should contain values that represent the\n",
    "    likelihood of the positive class, typically ranging between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Define the figure name and path\n",
    "    my_save_path = os.path.join(save_path, figure_name)\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Calculate False Positive Rate and True Positive Rate\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "    # Calculate AUC\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    # Plotting ROC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='darkgray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "    plt.savefig(my_save_path, format='png', bbox_inches='tight')\n",
    "    print(f\"Plot saved to {save_path} as {figure_name}\")\n",
    "    # plt.gcf().set_dpi(200)\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3448b5150ec3a180"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auc_skl = plot_roc_skl_binary(y_test, y_pred, SAVE_PATH, figure_name='my_plot_roc_sk.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82212644f6d57337"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auc_skl"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d6c54239b872ff1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the uploaded CSV file into a pandas DataFrame\n",
    "dataset_out = 'med_records_results.csv'\n",
    "folder_out = './projects_outscope'\n",
    "file_path_out = os.path.join(folder_out, dataset_out)\n",
    "\n",
    "data_frame = pd.read_csv(file_path_out)\n",
    "\n",
    "# Extract the two tables from the data frame\n",
    "y_test_out = data_frame[['y_test']].to_numpy()\n",
    "y_pred_out = data_frame[['y_pred']].to_numpy()\n",
    "\n",
    "# Display the first few rows of each table for confirmation\n",
    "y_test_out[:5], y_pred_out[:5]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c7cccdbd6fd37e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure_name_out = 'my_roc_out.png'\n",
    "my_auc_out = plot_roc_skl_binary(y_test_out, y_pred_out, folder_out, figure_name=figure_name_out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11197d7347147046"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "65df0b6886758ef7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
