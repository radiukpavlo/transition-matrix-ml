{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9429755869ff6538",
   "metadata": {},
   "source": [
    "## 1. Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde58ff0426c5dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "iris_features = iris.data\n",
    "iris_labels = iris.target\n",
    "iris_target_names = iris.target_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667114b9e58936a8"
  },
  {
   "cell_type": "markdown",
   "id": "e695dfea778f3996",
   "metadata": {},
   "source": [
    "## 2. Multi-dimensional scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e9e1eb4935bbd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris_features)\n",
    "\n",
    "# Apply MDS to reduce the dimensions to 2\n",
    "mds = MDS(n_components=2, normalized_stress='auto')\n",
    "X_mds = mds.fit_transform(X_scaled)\n",
    "\n",
    "# Apply t-SNE to reduce the dimensions to 2\n",
    "# tsne = TSNE(n_components=2, random_state=42, n_iter=500)\n",
    "# X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Convert the reduced data back to a pandas DataFrame\n",
    "iris_reduced = pd.DataFrame(X_mds, columns=[\"x1\", \"x2\"])\n",
    "iris_reduced['labels'] = iris_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53631ef3401b86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da81fd32728ac3",
   "metadata": {},
   "source": [
    "## 3. Visual analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b41a730c5cf71b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interpolate_coordinates(x_1, x_n, n):\n",
    "    \"\"\"\n",
    "    This function calculates the values of the interpolate_coordinates\n",
    "    of a line based on its first and last coordinates.\n",
    "    :param x_1:\n",
    "    :param x_n:\n",
    "    :param n:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Ensure n is greater than 1 to avoid division by zero\n",
    "    if n <= 1:\n",
    "        raise ValueError(\"n must be greater than 1 to calculate intermediate points.\")\n",
    "\n",
    "    # List to hold all the coordinates including the first and the last\n",
    "    inter_coordinates = []\n",
    "\n",
    "    # Calculate each intermediate coordinate\n",
    "    for i in range(0, n):\n",
    "        x_i = x_1 + ((x_n - x_1) * i) / (n - 1)\n",
    "        inter_coordinates.append(x_i)\n",
    "\n",
    "    return inter_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d400b47e30a90",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_1_first = 8\n",
    "x_2_first = 4\n",
    "\n",
    "x_1_last = 5\n",
    "x_2_last = -4\n",
    "\n",
    "# The number of intermediate points\n",
    "num_inter_points = iris_features.shape[1]\n",
    "\n",
    "x_1_inter_coordinates = interpolate_coordinates(x_1_first, x_1_last, num_inter_points)\n",
    "x_2_inter_coordinates = interpolate_coordinates(x_2_first, x_2_last, num_inter_points)\n",
    "# print(x_1_inter_coordinates)\n",
    "# print(x_2_inter_coordinates)\n",
    "\n",
    "# Create a DataFrame from the coordinates\n",
    "coordinates_df = pd.DataFrame({'x1': x_1_inter_coordinates, 'x2': x_2_inter_coordinates})\n",
    "coordinates_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "NUM_TICKS = 2\n",
    "\n",
    "# Define colors for each species\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Set tick frequency using MultipleLocator\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(NUM_TICKS))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(NUM_TICKS))\n",
    "\n",
    "# Plot each species\n",
    "for i, species in enumerate(iris_target_names):\n",
    "    subset = iris_reduced[iris_reduced['labels'] == i]\n",
    "    plt.scatter(subset['x1'], subset['x2'], color=colors[i], label=species)\n",
    "\n",
    "    # Annotate each point with its class label\n",
    "    for _, row in subset.iterrows():\n",
    "        plt.annotate(str(i), (row['x1'], row['x2']), textcoords=\"offset points\", xytext=(6, -6), ha='center', fontsize=8)\n",
    "\n",
    "# Draw the separating line\n",
    "line_x1 = coordinates_df['x1'].tolist()\n",
    "line_x2 = coordinates_df['x2'].tolist()\n",
    "plt.plot(line_x1, line_x2, 'k-')  # 'k-' for black line\n",
    "\n",
    "# Highlight points on the separating line\n",
    "# If coordinates_df contains these points, plot them with a distinct style\n",
    "plt.scatter(line_x1, line_x2, color='k', marker='o', edgecolor='k', label='Line Points')\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('MDS of Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "539e273fb1e88f6a"
  },
  {
   "cell_type": "markdown",
   "id": "ebc5f8d71f9e871e",
   "metadata": {},
   "source": [
    "## 4. Calculate Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef465326b3763a84",
   "metadata": {},
   "source": [
    "### 3.1. Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b16087dcd6299f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Receive values from the matrix A DataFrame \n",
    "formal_model_reduced_values = iris_reduced.drop('labels', axis=1).values\n",
    "\n",
    "# Calculate SVD\n",
    "U, s, Vt = np.linalg.svd(formal_model_reduced_values)\n",
    "\n",
    "# Construct the full diagonal matrix\n",
    "S = np.zeros(formal_model_reduced_values.shape)\n",
    "for i in range(min(formal_model_reduced_values.shape)):\n",
    "    S[i, i] = s[i]\n",
    "\n",
    "# print(\"U:\\n\", U)\n",
    "# print(\"\\nS:\\n\", S)\n",
    "# print(\"\\nVt:\\n\", Vt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "formal_model_reduced_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "819ac288e0668213"
  },
  {
   "cell_type": "markdown",
   "id": "20ecf1e1d1743431",
   "metadata": {},
   "source": [
    "### 3.2. Create the reconstructed matrix of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300dbbed7537914f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recompute the original matrix using U, S, and Vt\n",
    "reconstructed_matrix = U.dot(S.dot(Vt))\n",
    "\n",
    "# Convert the reconstructed matrix to a pandas DataFrame, if desired\n",
    "reconstructed_df = pd.DataFrame(reconstructed_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855a3fcf677b065",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstructed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9ceb900efd47d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22636c4bc2289d4",
   "metadata": {},
   "source": [
    "### 3.3. Calculate the generalized inverse of input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d42f8951a5a24",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the generalized (Moore-Penrose) inverse\n",
    "formal_model_reduced_pinv = np.linalg.pinv(formal_model_reduced_values)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "formal_model_reduced_pinv_df = pd.DataFrame(formal_model_reduced_pinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723de97150d5c16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formal_model_reduced_pinv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae217465b26b7db8",
   "metadata": {},
   "source": [
    "### 3.4. Calculate transition matrix T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df41ba6680071d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_matrix_T = formal_model_reduced_pinv_df.dot(iris_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f9ce7d7ea80a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_matrix_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63707c7d6fa3b351",
   "metadata": {},
   "source": [
    "## 4. Create Hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af020167e0a630b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinates_hyperplane_df = coordinates_df.values @ transition_matrix_T.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ccb2f95c82aa4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinates_hyperplane_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f055e528cfd8f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding a new column with all values set to 1\n",
    "new_column = np.ones((coordinates_hyperplane_df.shape[0], 1))\n",
    "feature_vector_inverse = np.hstack((new_column, coordinates_hyperplane_df))\n",
    "\n",
    "feature_vector_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5eee4c62ff7f6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimization criteria function\n",
    "def optimization_criteria(W, X):\n",
    "    return np.sum(np.abs(X.dot(W.T)))\n",
    "\n",
    "# Initial guess (starting point for the optimization algorithm)\n",
    "weights_inverse_initial = np.zeros(feature_vector_inverse.shape[1])\n",
    "\n",
    "# Bounds for W (setting it between -1 and 1)\n",
    "bounds = [(-1, 1) for _ in range(feature_vector_inverse.shape[1])]\n",
    "\n",
    "# The actual optimization\n",
    "res = minimize(\n",
    "    optimization_criteria,\n",
    "    weights_inverse_initial,\n",
    "    args=(feature_vector_inverse,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    options={'disp': True}\n",
    ")\n",
    "\n",
    "# Checking if the optimization was successful\n",
    "if res.success:\n",
    "    # Extract the weights into a DataFrame\n",
    "    weights_inverse_output = pd.DataFrame(res.x, index=[f'w{i}' for i in range(len(res.x))], columns=['weight'])\n",
    "\n",
    "    print(\"Optimization was successful. The weights are:\")\n",
    "    print(weights_inverse_output)\n",
    "\n",
    "    # Output the value of the optimization criteria\n",
    "    print(\"\\nValue of the optimization criteria (objective function value):\", res.fun)\n",
    "else:\n",
    "    print(\"Optimization failed.\")\n",
    "\n",
    "# Checking for convergence\n",
    "print(\"\\nConvergence status:\", res.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229473793e1f5f6d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_inverse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4510816a331570",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorder the weight vector so that w0 is at the end.\n",
    "weights_df_reordered = pd.concat([weights_inverse_output.iloc[1:], weights_inverse_output.iloc[0:1]]).reset_index(drop=True)\n",
    "\n",
    "# Show the modified DataFrame\n",
    "weights_df_reordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bb7858af12496",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert iris_features to a DataFrame\n",
    "# and an additional column\n",
    "new_formal_model_features = pd.DataFrame(iris_features, columns=iris.feature_names)\n",
    "new_formal_model_features['ones'] = 1\n",
    "new_formal_model_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f759c7f2967205",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Multiply the features by the weights\n",
    "my_result = new_formal_model_features.mul(weights_df_reordered['weight'].values, axis=1)\n",
    "\n",
    "# Sum along the rows to get the final single column for predictions\n",
    "my_predictions = my_result.sum(axis=1)\n",
    "\n",
    "# Convert the series to a data frame\n",
    "my_predictions_df = my_predictions.to_frame(name='Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d42fcab1156ca0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c176f0dcb5faa9c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_labels_df = pd.DataFrame(iris_labels, columns=['labels'])\n",
    "\n",
    "my_predictions_df = pd.concat([my_predictions_df, iris_labels_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92461bc9c2e37d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb3eed4a46abb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_predictions_df.to_csv('.\\projects_temp-data\\my_predictions_df_iris.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_positives_negatives(df):\n",
    "    \"\"\"\n",
    "    Count the number of positive and negative numbers in the 'Prediction' column for each unique value in the 'Target' column.\n",
    "\n",
    "    :param df: DataFrame with 'Target' and 'Prediction' columns\n",
    "    :return: DataFrame with the count of positive and negative predictions for each target\n",
    "    \"\"\"\n",
    "    # Group by 'Target' and then apply the counting logic\n",
    "    result = df.groupby('labels')['Prediction'].agg(\n",
    "        positive_count=lambda x: (x > 0).sum(),\n",
    "        negative_count=lambda x: (x < 0).sum(),\n",
    "        sum=lambda x: x.count()\n",
    "    ).reset_index()\n",
    "\n",
    "    return result\n",
    "\n",
    "# Apply the function to the predictions DataFrame\n",
    "result_df = count_positives_negatives(my_predictions_df)\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6120623a92febffe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bfa80004bee706aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
