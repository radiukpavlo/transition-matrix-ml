{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vex99np2wFVt"
   },
   "source": [
    "# 03. PyTorch Computer Vision Exercise Solutions\n",
    "\n",
    "The following is one possible set (there may be more than one way to do things) of solutions for the 03. PyTorch Computer Vision exercise template.\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises/solutions are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
    "  * **Note:** Going through these exercises took me just over 3 hours, so you should expect around the same.\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GaeYzOTLwWh2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805496136,
     "user_tz": -180,
     "elapsed": 2,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:28.640102300Z",
     "start_time": "2023-07-31T12:38:28.407236800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "6f485cb7-2edc-4e09-d1dd-79af23a6052a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805501014,
     "user_tz": -180,
     "elapsed": 4880,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:28.796940800Z",
     "start_time": "2023-07-31T12:38:28.410228300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFX7tc1w-en"
   },
   "source": [
    "## 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmB6iAzN1X4u"
   },
   "source": [
    "1. Self-driving cars, such as Tesla using computer vision to percieve what's happening on the road. See Tesla AI day for more - https://youtu.be/j0z4FweCy4M\n",
    "2. Healthcare imaging, such as using computer vision to help interpret X-rays. Google also uses computer vision for detecting polyps in the intenstines - https://ai.googleblog.com/2021/08/improved-detection-of-elusive-polyps.html\n",
    "3. Security, computer vision can be used to detect whether someone is invading your home or not - https://store.google.com/au/product/nest_cam_battery?hl=en-GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBK-WI6YxDYa"
   },
   "source": [
    "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMLaps1J3pJ_"
   },
   "source": [
    "Overfitting is like memorizing for a test, but then you can't answer a question that's slightly different.\n",
    "\n",
    "In other words, if a model is overfitting, it's learning the training data *too well* and these patterns don't generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYFEqw8xK26"
   },
   "source": [
    "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
    "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9Hdd08s4kvN"
   },
   "source": [
    "See this article for some ideas: https://elitedatascience.com/overfitting-in-machine-learning\n",
    "\n",
    "3 ways to prevent overfitting:\n",
    "1. **Regularization techniques** - You could use [dropout on your neural networks](https://en.wikipedia.org/wiki/Dilution_(neural_networks)), dropout involves randomly removing neurons in different layers so that the remaining neurons hopefully learn more robust weights/patterns.\n",
    "2. **Use a different model** - maybe the model you're using for a specific problem is too complicated, as in, it's learning the data too well because it has so many layers. You could remove some layers to simplify your model. Or you could pick a totally different model altogether, one that may be more suited to your particular problem. Or... you could also use [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) (taking the patterns from one model and applying them to your own problem).\n",
    "3. **Reduce noise in data/cleanup dataset/introduce data augmentation techniques** - If the model is learning the data too well, it might be just memorizing the data, including the noise. One option would be to remove the noise/clean up the dataset or if this doesn't, you can introduce artificial noise through the use of data augmentation to artificially increase the diversity of your training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKdEEFEqxM-8"
   },
   "source": [
    "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnUox1qayDes"
   },
   "source": [
    "The CNN explainer website is a great insight into all the nuts and bolts of a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf-3pODxXYI"
   },
   "source": [
    "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "rV7s2qtIyDIZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805501014,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:28.907727800Z",
     "start_time": "2023-07-31T12:38:28.448472800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tVnyuGku9m0y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502075,
     "user_tz": -180,
     "elapsed": 1064,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "outputId": "642c8856-c82e-41da-8944-026a7fa3d96a",
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.248172600Z",
     "start_time": "2023-07-31T12:38:28.457008300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the MNIST train dataset\n",
    "train_data = datasets.MNIST(root=\".\",\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor()) # do we want to transform the data as we download it?\n",
    "\n",
    "# Get the MNIST test dataset\n",
    "test_data = datasets.MNIST(root=\".\",\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaj7vnOv-cB2",
    "outputId": "9fc4bdf8-aef2-4b13-cb5c-bac8f532fd96",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502076,
     "user_tz": -180,
     "elapsed": 16,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.248172600Z",
     "start_time": "2023-07-31T12:38:28.518461300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(Dataset MNIST\n     Number of datapoints: 60000\n     Root location: .\n     Split: Train\n     StandardTransform\n Transform: ToTensor(),\n Dataset MNIST\n     Number of datapoints: 10000\n     Root location: .\n     Split: Test\n     StandardTransform\n Transform: ToTensor())"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUZMY9xR-sfH",
    "outputId": "0d90f988-6e12-4079-ad9c-b7e616fc1247",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502076,
     "user_tz": -180,
     "elapsed": 14,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.249171600Z",
     "start_time": "2023-07-31T12:38:28.535936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 10000)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "THsDkX0K-gUk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502076,
     "user_tz": -180,
     "elapsed": 13,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.249171600Z",
     "start_time": "2023-07-31T12:38:28.551686200Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Data is in tuple form (image, label)\n",
    "# img = train_data[2][0]\n",
    "# label = train_data[2][1]\n",
    "# print(f\"Image:\\n {img}\")\n",
    "# print(f\"Label:\\n {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "txys9vVXAUPs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502076,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.253160300Z",
     "start_time": "2023-07-31T12:38:28.565198900Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Check out the shapes of our data\n",
    "# print(f\"Image shape: {img.shape} -> [color_channels, height, width] (CHW)\")\n",
    "# print(f\"Label: {label} -> no shape, due to being integer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS3XHDW6AuJs"
   },
   "source": [
    "Note: There are two main agreed upon ways for representing images in machine learning:\n",
    "1. Color channels first: [color_channels, height, width] (CHW) -> PyTorch default (as of April 2022)\n",
    "2. Color channels last: [height, width, color_channels] (HWC) -> Matplotlib/TensorFlow default (as of April 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7UEVf8B_JuK",
    "outputId": "66545de9-d5a7-433c-8409-bf53a7f6aabb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502076,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.307884400Z",
     "start_time": "2023-07-31T12:38:28.582794200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['0 - zero',\n '1 - one',\n '2 - two',\n '3 - three',\n '4 - four',\n '5 - five',\n '6 - six',\n '7 - seven',\n '8 - eight',\n '9 - nine']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the class names from the dataset\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxZW-uAbxe_F"
   },
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "HdRM86voyC0x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502077,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.307884400Z",
     "start_time": "2023-07-31T12:38:28.596318200Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for i in range(5):\n",
    "#   img = train_data[i][0]\n",
    "#   print(img.shape)\n",
    "#   img_squeeze = img.squeeze()\n",
    "#   print(img_squeeze.shape)\n",
    "#   label = train_data[i][1]\n",
    "#   plt.figure(figsize=(3, 3))\n",
    "#   plt.imshow(img_squeeze, cmap=\"gray\")\n",
    "#   plt.title(label)\n",
    "#   plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPDzW0wxhi3"
   },
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Cz09bv8KCnCa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502077,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.307884400Z",
     "start_time": "2023-07-31T12:38:28.613107200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create train dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=16,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=16,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tWfa7Y0yCkX",
    "outputId": "24f1cb50-fa16-43c1-befe-dbe50f84871f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502077,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.309881600Z",
     "start_time": "2023-07-31T12:38:28.628613500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(<torch.utils.data.dataloader.DataLoader at 0x1f7d817a7f0>,\n <torch.utils.data.dataloader.DataLoader at 0x1f7d817a100>)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2-3iYEgD8K-",
    "outputId": "54d98ea6-8bc4-4bb3-b5c3-2202de665888",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502077,
     "user_tz": -180,
     "elapsed": 11,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.327927800Z",
     "start_time": "2023-07-31T12:38:28.642096600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for sample in next(iter(train_dataloader)):\n",
    "  print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfSrUoa9Eb3V",
    "outputId": "25452e5b-2005-4633-da31-bab133191e8c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805502077,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.350942800Z",
     "start_time": "2023-07-31T12:38:28.660087400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(3750, 625)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCVfXk5xjYS"
   },
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "xeBNV2AtyCP6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805503056,
     "user_tz": -180,
     "elapsed": 988,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.350942800Z",
     "start_time": "2023-07-31T12:38:28.680057200Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MNISTModel(torch.nn.Module):\n",
    "  \"\"\"Model capable of predicting on MNIST dataset.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=hidden_units*7*7,\n",
    "                out_features=output_shape)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = self.conv_block_1(x)\n",
    "    print(f\"Output shape of conv block 1: {x.shape}\")\n",
    "    x = self.conv_block_2(x)\n",
    "    print(f\"Output shape of conv block 2: {x.shape}\")\n",
    "    # Before applying classifier, just flatten and print the shape\n",
    "    x_flattened = nn.Flatten()(x) # Flatten the tensor\n",
    "    self.get_flatten = nn.Flatten()(x) # flatten and save to a class attribute\n",
    "    print(f\"Shape after flattening: {x_flattened.shape}\")\n",
    "    x = self.classifier(x)\n",
    "    print(f\"Output shape of classifier: {x.shape}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Pfk9zykYK0FM",
    "outputId": "b257e814-4ccc-4766-e019-3b47a8cd2cb0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805503057,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.350942800Z",
     "start_time": "2023-07-31T12:38:28.694030300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPmadzsTJndN",
    "outputId": "599bad6a-ac98-41d2-b6e2-8ef6fa4a1207",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805507466,
     "user_tz": -180,
     "elapsed": 4412,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.351939700Z",
     "start_time": "2023-07-31T12:38:28.706015400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MNISTModel(\n  (conv_block_1): Sequential(\n    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_block_2): Sequential(\n    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=490, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTModel(input_shape=1,\n",
    "                    hidden_units=10,\n",
    "                    output_shape=10).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkFZjQR_mIQP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515743,
     "user_tz": -180,
     "elapsed": 8281,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "outputId": "dbf74a87-6ac8-43bf-ef65-00bc4791496d",
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.351939700Z",
     "start_time": "2023-07-31T12:38:28.720495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "Output shape of conv block 1: torch.Size([1, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([1, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([1, 490])\n",
      "Output shape of classifier: torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0169,  0.1171,  0.0420, -0.0589,  0.0659,  0.0494, -0.0658, -0.0076,\n         -0.0800, -0.0294]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random input tensor with the shape that matches a single MNIST image (1, 28, 28)\n",
    "# Note: The first 1 is the batch size, indicating we're feeding 1 image.\n",
    "my_input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
    "print(my_input_tensor.shape)\n",
    "\n",
    "# Pass the input tensor through the model to print the output shapes of each block\n",
    "my_output = model(my_input_tensor)\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ExNGpLz9LfOO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515743,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.351939700Z",
     "start_time": "2023-07-31T12:38:28.736477900Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Check out the model state dict to find out what patterns our model wants to learn\n",
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vqiDj2wmIQQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515743,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "outputId": "6f9625b8-b3ea-4d68-bc80-b6fd0f3f08b6",
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.352937Z",
     "start_time": "2023-07-31T12:38:28.753956700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0138,  0.0172, -0.0006,  ...,  0.0217,  0.0006, -0.0057],\n",
      "        [-0.0292,  0.0430,  0.0013,  ...,  0.0050,  0.0397,  0.0304],\n",
      "        [ 0.0048,  0.0255, -0.0440,  ...,  0.0383,  0.0124, -0.0442],\n",
      "        ...,\n",
      "        [-0.0128,  0.0348,  0.0074,  ..., -0.0047, -0.0091, -0.0063],\n",
      "        [-0.0238, -0.0108,  0.0312,  ...,  0.0419,  0.0379,  0.0124],\n",
      "        [-0.0182,  0.0352, -0.0056,  ..., -0.0225, -0.0159, -0.0084]])\n",
      "tensor([-0.0398,  0.0268,  0.0395, -0.0339,  0.0251,  0.0229, -0.0304,  0.0291,\n",
      "        -0.0357, -0.0348])\n"
     ]
    }
   ],
   "source": [
    "weights = model.classifier[1].weight.data\n",
    "bias = model.classifier[1].bias.data\n",
    "\n",
    "print(weights)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAd-DhBIMQ_N",
    "outputId": "41539813-ac24-4f70-e981-79dbe75a82d4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515744,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.352937Z",
     "start_time": "2023-07-31T12:38:28.767959200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "Output shape of conv block 1: torch.Size([1, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([1, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([1, 490])\n",
      "Output shape of classifier: torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0290,  0.0952,  0.0338, -0.0519,  0.0631,  0.0366, -0.0592,  0.0040,\n         -0.0691, -0.0288]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a dummy forward pass to see what shapes our data is\n",
    "dummy_x = torch.rand(size=(1, 28, 28)).unsqueeze(dim=0).to(device)\n",
    "\n",
    "print(dummy_x.shape)\n",
    "model(dummy_x)\n",
    "# dummy_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw4nqMCVN_Jr",
    "outputId": "1ae808b8-bf86-4f09-e3b5-c7f1ae24f102",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515744,
     "user_tz": -180,
     "elapsed": 9,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.353934200Z",
     "start_time": "2023-07-31T12:38:28.783425500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10, 7, 7])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x_2 = torch.rand(size=([1, 10, 7, 7]))\n",
    "dummy_x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9omFrrBCODLL",
    "outputId": "522bff81-bb6f-4962-e43f-de93fcd8d9b3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515744,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.354931800Z",
     "start_time": "2023-07-31T12:38:28.800102300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 490])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer = nn.Flatten()\n",
    "flatten_layer(dummy_x_2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkE8puBImIQR"
   },
   "source": [
    "## 9. Train the model you built in exercise 8 for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "in8DzC6tmIQR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805515744,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-31T12:38:29.561732800Z",
     "start_time": "2023-07-31T12:38:28.817082300Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from tqdm.auto import tqdm\n",
    "#\n",
    "# # Train on CPU\n",
    "# model_cpu = MNISTModel(input_shape=1,\n",
    "#                         hidden_units=10,\n",
    "#                         output_shape=10).to(\"cpu\")\n",
    "#\n",
    "# # Create a loss function and optimizer\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model_cpu.parameters(), lr=0.1)\n",
    "#\n",
    "# ### Training loop\n",
    "# epochs = 5\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#   train_loss = 0\n",
    "#   for batch, (X, y) in enumerate(train_dataloader):\n",
    "#     model_cpu.train()\n",
    "#\n",
    "#     # Put data on CPU\n",
    "#     X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "#\n",
    "#     # Forward pass\n",
    "#     y_pred = model_cpu(X)\n",
    "#\n",
    "#     # Loss calculation\n",
    "#     loss = loss_fn(y_pred, y)\n",
    "#     train_loss += loss\n",
    "#\n",
    "#     # Optimizer zero grad\n",
    "#     optimizer.zero_grad()\n",
    "#\n",
    "#     # Loss backward\n",
    "#     loss.backward()\n",
    "#\n",
    "#     # Step the optimizer\n",
    "#     optimizer.step()\n",
    "#\n",
    "#   # Adjust train loss for number of batches\n",
    "#   train_loss /= len(train_dataloader)\n",
    "#\n",
    "#   ### Testing loop\n",
    "#   test_loss_total = 0\n",
    "#\n",
    "#   # Put model in eval mode\n",
    "#   model_cpu.eval()\n",
    "#\n",
    "#   # Turn on inference mode\n",
    "#   with torch.inference_mode():\n",
    "#     for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "#       # Make sure test data on CPU\n",
    "#       X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\n",
    "#       test_pred = model_cpu(X_test)\n",
    "#       test_loss = loss_fn(test_pred, y_test)\n",
    "#\n",
    "#       test_loss_total += test_loss\n",
    "#\n",
    "#     test_loss_total /= len(test_dataloader)\n",
    "#\n",
    "#   # Print out what's happening\n",
    "#   print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b2be661e7414444eafefc50786dd9b76",
      "2239f77486f348f989463de8eee7fbe9",
      "635e558c36e8415cafe69e315c70d1dd",
      "d73b703d06ee496781d48080e82edcd7",
      "04ed2a1850624ea3a724daf1f82c5383",
      "96f1ccc77d3641718bf41245e0c1c8c1",
      "fac90735353a4755935a42a125a72a73",
      "2691f9aec2614a1298133154a552dc71",
      "11b3193c755d4b91becf14efa1c443f0",
      "540f82a2be3d4f629c6a6f0b2713fa07",
      "b89e38295f934a4785756a4741ab1055"
     ]
    },
    "id": "0IzzuVLkPE9j",
    "outputId": "4007733b-461f-4a00-bb9d-b636db10f0cb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805570724,
     "user_tz": -180,
     "elapsed": 54986,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-31T12:38:28.830700600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n",
      "Output shape of conv block 1: torch.Size([16, 10, 14, 14])\n",
      "Output shape of conv block 2: torch.Size([16, 10, 7, 7])\n",
      "Shape after flattening: torch.Size([16, 490])\n",
      "Output shape of classifier: torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Train on GPU\n",
    "model_gpu = MNISTModel(input_shape=1,\n",
    "                        hidden_units=10,\n",
    "                        output_shape=10).to(device)\n",
    "\n",
    "# Create a loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_gpu.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "epochs = 2\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  train_loss = 0\n",
    "  model_gpu.train()\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    # Put data on target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model_gpu(X)\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "\n",
    "    # Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust train loss to number of batches\n",
    "  train_loss /= len(train_dataloader)\n",
    "\n",
    "  ### Testing loop\n",
    "  test_loss_total = 0\n",
    "  # Put model in eval mode and turn on inference mode\n",
    "  model_gpu.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "      # Make sure test data on target device\n",
    "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "      test_pred = model_gpu(X_test)\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "    # Adjust test loss total for number of batches\n",
    "    test_loss_total /= len(test_dataloader)\n",
    "\n",
    "  # Print out what's happening\n",
    "  print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1CsHhPpxp1w"
   },
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "iVyM5cC6yBkF",
    "outputId": "d6311b6e-b081-41dd-bc92-080b5f439c47",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805570725,
     "user_tz": -180,
     "elapsed": 18,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Make predictions with the trained model\n",
    "plt.imshow(test_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGide8hMWP17",
    "outputId": "be7490a9-d239-426b-c2de-0e48f185ab3b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805570725,
     "user_tz": -180,
     "elapsed": 16,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Logits -> Prediction probabilities -> Prediction labels\n",
    "model_pred_logits = model_gpu(test_data[0][0].unsqueeze(dim=0).to(device)) # make sure image is right shape + on right device\n",
    "model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "model_pred_label = torch.argmax(model_pred_probs, dim=1)\n",
    "model_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNCPUtO_Wuj5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805570725,
     "user_tz": -180,
     "elapsed": 14,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "558df7c7-3c11-4ada-c37c-49857d9f133f",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "num_to_plot = 5\n",
    "for i in range(num_to_plot):\n",
    "  # Get image and labels from the test data\n",
    "  img = test_data[i][0]\n",
    "  label = test_data[i][1]\n",
    "\n",
    "  # Make prediction on image\n",
    "  model_pred_logits = model_gpu(img.unsqueeze(dim=0).to(device))\n",
    "  model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "  model_pred_label = torch.argmax(model_pred_probs, dim=1)\n",
    "\n",
    "  # # Plot the image and prediction\n",
    "  # plt.figure()\n",
    "  # plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "  # plt.title(f\"Truth: {label} | Pred: {model_pred_label.cpu().item()}\")\n",
    "  # plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# drive_path = \"/content/drive/My Drive/Colab Notebooks/mnist\"\n",
    "# drive_path = r\"D:\\GitHub\\transition-matrix-ml\\notebooks\"\n",
    "drive_path = r\"C:\\Courses\\transition-matrix-ml\\mnist\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_ELulZFo9_p",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805883800,
     "user_tz": -180,
     "elapsed": 2639,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "outputId": "2b688f21-6e61-443f-a0b2-2c4b9550535e",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sample_dataset(train_data):\n",
    "    \"\"\"\n",
    "    This function creates a new dataset subset with the\n",
    "    specified number of samples.\n",
    "    :param train_data: Original training dataset\n",
    "    :return: Subset of the training dataset\n",
    "            and a list of unique IDs (indices from the original dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    n_samples = 1000\n",
    "\n",
    "    labels = train_data.targets.numpy()\n",
    "\n",
    "    # Determine the proportion of each class in the training dataset\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    proportions = counts / len(labels)\n",
    "\n",
    "    # Determine the number of samples to extract for each class\n",
    "    samples_per_class = (proportions * n_samples).astype(int)\n",
    "\n",
    "    # Extract samples based on the proportions\n",
    "    indices_to_extract = []\n",
    "\n",
    "    for label, n_samples in enumerate(samples_per_class):\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        chosen_indices = np.random.choice(label_indices, n_samples, replace=False)\n",
    "        indices_to_extract.extend(chosen_indices)\n",
    "\n",
    "    # Shuffle the indices for randomness\n",
    "    # np.random.shuffle(indices_to_extract)\n",
    "\n",
    "    # Return a subset of the dataset\n",
    "    sample_dataset = torch.utils.data.Subset(train_data, indices_to_extract)\n",
    "\n",
    "    return sample_dataset, indices_to_extract\n"
   ],
   "metadata": {
    "id": "ibLxia7Qo5t-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805892873,
     "user_tz": -180,
     "elapsed": 485,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "my_sample_dataset, my_indices = generate_sample_dataset(train_data)"
   ],
   "metadata": {
    "id": "2hIelW6nvehF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805898732,
     "user_tz": -180,
     "elapsed": 1,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "n_pixels = 784\n",
    "\n",
    "# Save the images and labels to a CSV file in Google Drive\n",
    "with open(f\"{drive_path}/mnist_subset.csv\", \"w\", newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Header\n",
    "    header = [\"unique_id\", \"label\"] + [\"pixel\" + str(i) for i in range(n_pixels)]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Rows\n",
    "    for idx, (image, label) in zip(my_indices, my_sample_dataset):\n",
    "        image = image[0].numpy().flatten()  # Extract the tensor from the tuple\n",
    "        row = [idx, label] + image.tolist()\n",
    "        csv_writer.writerow(row)\n"
   ],
   "metadata": {
    "id": "z1O2qfPTuA3U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805902467,
     "user_tz": -180,
     "elapsed": 611,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czewqwIJmIQd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805906678,
     "user_tz": -180,
     "elapsed": 1,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def generate_prediction_weights(input_dataset):\n",
    "    \"\"\"\n",
    "    This function extracts the weights from the model in the prediction stage\n",
    "    :param input_dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    total_images = len(input_dataset)\n",
    "\n",
    "    my_pred_flattened = []\n",
    "    my_pred_logits = []\n",
    "    my_label_preds = []\n",
    "    my_label_real = []\n",
    "\n",
    "    for item in range(total_images):\n",
    "        # Get image and labels from the test data\n",
    "        input_image = input_dataset[item][0]\n",
    "        input_label = input_dataset[item][1]\n",
    "        my_label_real.append(input_label)\n",
    "\n",
    "        # Extract and save the weights after the nn.Flatten() layer\n",
    "        model_pred_flattened = model.get_flatten\n",
    "        my_pred_flattened.append(model_pred_flattened)\n",
    "\n",
    "        # Save the prediction weights\n",
    "        model_pred_logits = model_gpu(input_image.unsqueeze(dim=0).to(device))\n",
    "        my_pred_logits.append(model_pred_logits)\n",
    "\n",
    "        # Save the prediction labels\n",
    "        model_pred_labels = torch.argmax(torch.softmax(model_pred_logits, dim=1), dim=1)\n",
    "        my_label_preds.append(model_pred_labels)\n",
    "\n",
    "    my_pred_flattened = torch.cat(my_pred_flattened).cpu()\n",
    "    my_pred_logits = torch.cat(my_pred_logits).cpu()\n",
    "    my_label_preds = torch.cat(my_label_preds).cpu()\n",
    "\n",
    "    return my_pred_flattened, my_pred_logits, my_label_preds, my_label_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcfdHv_pmIQd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805913891,
     "user_tz": -180,
     "elapsed": 2356,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6dbadf74-1445-4830-8724-c095be2ef938",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "my_prediction_weights = generate_prediction_weights(my_sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMYLfeE3mIQd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805920756,
     "user_tz": -180,
     "elapsed": 1767,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# print(my_pred_logits.type)\n",
    "# print(my_label_preds)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def tensor_to_dataframe(tensor):\n",
    "    \"\"\"Convert a PyTorch tensor to a pandas DataFrame.\"\"\"\n",
    "    return pd.DataFrame(tensor.cpu().detach().numpy())\n",
    "\n",
    "# Convert the tensor to a DataFrame\n",
    "df_flattened = tensor_to_dataframe(my_prediction_weights[0])\n",
    "df_logits = tensor_to_dataframe(my_prediction_weights[1])\n",
    "df_preds = tensor_to_dataframe(my_prediction_weights[2])\n",
    "df_labels = pd.DataFrame(my_prediction_weights[3])\n",
    "\n",
    "# df_logits = pd.DataFrame(numpy_logits)\n",
    "# df_preds = pd.DataFrame(numpy_preds)\n",
    "\n",
    "# Save the DataFrame to a CSV file in\n",
    "# df_flattened.to_csv('./mnist/mnist_flattened.csv', index=False)\n",
    "# df_logits.to_csv('./mnist/mnist_logits.csv', index=False)\n",
    "# df_preds.to_csv('./mnist/mnist_preds.csv', index=False)\n",
    "# df_labels.to_csv('./mnist/mnist_labels.csv', index=False)\n",
    "\n",
    "# Save the DataFrame to a CSV file in Google Drive\n",
    "with open(f'{drive_path}/mnist_flattened.csv', 'w', encoding='utf-8-sig') as flattened:\n",
    "    df_flattened.to_csv(flattened)\n",
    "with open(f'{drive_path}/mnist_logits.csv', 'w', encoding='utf-8-sig') as logits:\n",
    "    df_logits.to_csv(logits)\n",
    "with open(f'{drive_path}/mnist_preds.csv', 'w', encoding='utf-8-sig') as preds:\n",
    "    df_preds.to_csv(preds)\n",
    "with open(f'{drive_path}/mnist_labels.csv', 'w', encoding='utf-8-sig') as labels:\n",
    "    df_labels.to_csv(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQwzqlBWxrpG"
   },
   "source": [
    "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTIlKRqqYF02",
    "outputId": "fe9d072c-a760-4d07-9682-b73a22e07f57",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805934993,
     "user_tz": -180,
     "elapsed": 6082,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # See if torchmetrics exists, if not, install it\n",
    "# try:\n",
    "#     import torchmetrics, mldxtend\n",
    "#     print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "#     assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19.0 or higher\"\n",
    "# except:\n",
    "#     !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
    "#     import torchmetrics, mlxtend\n",
    "#     print(f\"mlxtend version: {mlxtend.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqYUDscuYGSd",
    "outputId": "051c47e0-1d7c-41e3-b8e8-b5e6602da52f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805934993,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Import mlxtend upgraded version\n",
    "import mlxtend\n",
    "print(mlxtend.__version__)\n",
    "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be versioned 0.19.0 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "75a9f356c1574bf3ab38e73d0144b344",
      "c12b0b3950df471bb5b822f1afce9046",
      "acb8fdb3932945d4b07232dee71fface",
      "568a368e8b094ec19c16f92281859c1c",
      "182de626138f4fc5abec16510f997cf9",
      "1312213efa0348c8b426c32fd115fa5c",
      "3bd67740fd3d41e9bbd6112e3417cc58",
      "f22ac599ac61405fb3fac039379f03f0",
      "076e6e7c43b74724a94383ee353dc0a1",
      "c22f6b739ca5473e8e612277dc267fa0",
      "2edb0a13541a4dc79354be2ea3c6916f"
     ]
    },
    "id": "8kJO6BqAyBEc",
    "outputId": "798eb44c-8729-417e-9b3e-d0b3ceda16cd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805938586,
     "user_tz": -180,
     "elapsed": 3598,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Make predictions across all test data\n",
    "from tqdm.auto import tqdm\n",
    "model_gpu.eval()\n",
    "y_preds = []\n",
    "with torch.inference_mode():\n",
    "    for batch, (X, y) in tqdm(enumerate(test_dataloader)):\n",
    "        # Make sure data on right device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Forward pass\n",
    "        y_pred_logits = model_gpu(X)\n",
    "        # Logits -> Pred probs -> Pred label\n",
    "        y_pred_labels = torch.argmax(torch.softmax(y_pred_logits, dim=1), dim=1)\n",
    "        # Append the labels to the preds list\n",
    "        y_preds.append(y_pred_labels)\n",
    "    y_preds = torch.cat(y_preds).cpu()\n",
    "len(y_preds)\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMs7XPLTZBV4",
    "outputId": "fb270694-bcfd-44b8-d13a-638c9bdf09c3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805938586,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_data.targets[:10], y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "7lK_v2JyZOOG",
    "outputId": "021e9936-a16f-4485-e9cf-40357d039611",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690805939399,
     "user_tz": -180,
     "elapsed": 815,
     "user": {
      "displayName": "Pavlo Radiuk",
      "userId": "14186362969234732176"
     }
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# Setup confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_preds,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fix, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj6bDhoWxt2y"
   },
   "source": [
    "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7NdlYAKmIQf"
   },
   "source": [
    "random_tensor = torch.rand([1, 3, 64, 64])\n",
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzJLP6XqmIQf"
   },
   "source": [
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=64,\n",
    "                       kernel_size=3,\n",
    "                       stride=2,\n",
    "                       padding=1)\n",
    "\n",
    "print(f\"Random tensor original shape: {random_tensor.shape}\")\n",
    "random_tensor_through_conv_layer = conv_layer(random_tensor)\n",
    "print(f\"Random tensor through conv layer shape: {random_tensor_through_conv_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHS20cNTxwSi"
   },
   "source": [
    "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
    "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
    "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
    "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VgZt5POmIQf"
   },
   "source": [
    "# Download FashionMNIST train & test\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "fashion_mnist_train = datasets.FashionMNIST(root=\".\",\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "fashion_mnist_test = datasets.FashionMNIST(root=\".\",\n",
    "                                           train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "len(fashion_mnist_train), len(fashion_mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wctAWxjmIQg"
   },
   "source": [
    "# Get the class names of the Fashion MNIST dataset\n",
    "fashion_mnist_class_names = fashion_mnist_train.classes\n",
    "fashion_mnist_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReIeE__tmIQh"
   },
   "source": [
    "# Turn FashionMNIST datasets into dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "fashion_mnist_train_dataloader = DataLoader(fashion_mnist_train,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True)\n",
    "\n",
    "fashion_mnist_test_dataloader = DataLoader(fashion_mnist_test,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=False)\n",
    "\n",
    "len(fashion_mnist_train_dataloader), len(fashion_mnist_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AteaZRpxmIQh"
   },
   "source": [
    "# model_2 is the same architecture as MNISTModel\n",
    "model_2 = MNISTModel(input_shape=1,\n",
    "                      hidden_units=10,\n",
    "                      output_shape=10).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBvSxHM-mIQi"
   },
   "source": [
    "# Setup loss and optimizer\n",
    "from torch import nn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Cqdy143mIQi"
   },
   "source": [
    "# Setup metrics\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "acc_fn = Accuracy(task=\"multiclass\", num_classes=len(fashion_mnist_class_names)).to(device)\n",
    "\n",
    "# Setup training/testing loop\n",
    "epochs = 2\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  train_loss, test_loss_total = 0, 0\n",
    "  train_acc, test_acc = 0, 0\n",
    "\n",
    "  ### Training\n",
    "  model_2.train()\n",
    "  for batch, (X_train, y_train) in enumerate(fashion_mnist_train_dataloader):\n",
    "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "    # Forward pass and loss\n",
    "    y_pred = model_2(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    train_loss += loss\n",
    "    train_acc += acc_fn(y_pred, y_train)\n",
    "\n",
    "    # Backprop and gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust the loss/acc (find the loss/acc per epoch)\n",
    "  train_loss /= len(fashion_mnist_train_dataloader)\n",
    "  train_acc /= len(fashion_mnist_train_dataloader)\n",
    "\n",
    "  ### Testing\n",
    "  model_2.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(fashion_mnist_test_dataloader):\n",
    "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "      # Forward pass and loss\n",
    "      y_pred_test = model_2(X_test)\n",
    "      test_loss = loss_fn(y_pred_test, y_test)\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "      test_acc += acc_fn(y_pred_test, y_test)\n",
    "  \n",
    "    # Adjust the loss/acc (find the loss/acc per epoch)\n",
    "    test_loss /= len(fashion_mnist_test_dataloader)\n",
    "    test_acc /= len(fashion_mnist_test_dataloader)\n",
    "    \n",
    "  # Print out what's happening\n",
    "  print(f\"Epoch: {epoch} | Train loss: {train_loss:.3f} | Train acc: {train_acc:.2f} | Test loss: {test_loss_total:.3f} | Test acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ysX-JSKmIQi"
   },
   "source": [
    "# Make predictions with trained model_2\n",
    "test_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "  for X_test, y_test in tqdm(fashion_mnist_test_dataloader):\n",
    "    y_logits = model_2(X_test.to(device))\n",
    "    y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "    y_pred_labels = torch.argmax(y_pred_probs, dim=1)\n",
    "    test_preds.append(y_pred_labels)\n",
    "test_preds = torch.cat(test_preds).cpu() # matplotlib likes CPU\n",
    "test_preds[:10], len(test_preds)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amjDUjkSmIQi"
   },
   "source": [
    "# Get wrong prediction indexes\n",
    "import numpy as np\n",
    "wrong_pred_indexes = np.where(test_preds != fashion_mnist_test.targets)[0]\n",
    "len(wrong_pred_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TXBJdZ3mIQi"
   },
   "source": [
    "# Select random 9 wrong predictions and plot them\n",
    "import random\n",
    "random_selection = random.sample(list(wrong_pred_indexes), k=9)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, idx in enumerate(random_selection):\n",
    "  # Get true and pred labels\n",
    "  true_label = fashion_mnist_class_names[fashion_mnist_test[idx][1]]\n",
    "  pred_label = fashion_mnist_class_names[test_preds[idx]]\n",
    "\n",
    "  # Plot the wrong prediction with its original label\n",
    "  plt.subplot(3, 3, i+1)\n",
    "  plt.imshow(fashion_mnist_test[idx][0].squeeze(), cmap=\"gray\")\n",
    "  plt.title(f\"True: {true_label} | Pred: {pred_label}\", c=\"r\")\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoDfh-fKXtyU"
   },
   "source": [
    "From the look of some of these predictions, the model is getting about as confused as I would...\n",
    "\n",
    "For example it predicts \"Sneaker\" instead of \"Sandal\" when it could have easily been a \"Sneaker\".\n",
    "\n",
    "The same goes for the confusion between the classes of \"T-shirt/top\" and \"Shirt\", many of the examples here look similar."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b2be661e7414444eafefc50786dd9b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2239f77486f348f989463de8eee7fbe9",
       "IPY_MODEL_635e558c36e8415cafe69e315c70d1dd",
       "IPY_MODEL_d73b703d06ee496781d48080e82edcd7"
      ],
      "layout": "IPY_MODEL_04ed2a1850624ea3a724daf1f82c5383"
     }
    },
    "2239f77486f348f989463de8eee7fbe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96f1ccc77d3641718bf41245e0c1c8c1",
      "placeholder": "​",
      "style": "IPY_MODEL_fac90735353a4755935a42a125a72a73",
      "value": "100%"
     }
    },
    "635e558c36e8415cafe69e315c70d1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2691f9aec2614a1298133154a552dc71",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11b3193c755d4b91becf14efa1c443f0",
      "value": 2
     }
    },
    "d73b703d06ee496781d48080e82edcd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_540f82a2be3d4f629c6a6f0b2713fa07",
      "placeholder": "​",
      "style": "IPY_MODEL_b89e38295f934a4785756a4741ab1055",
      "value": " 2/2 [00:54&lt;00:00, 26.93s/it]"
     }
    },
    "04ed2a1850624ea3a724daf1f82c5383": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96f1ccc77d3641718bf41245e0c1c8c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fac90735353a4755935a42a125a72a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2691f9aec2614a1298133154a552dc71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11b3193c755d4b91becf14efa1c443f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "540f82a2be3d4f629c6a6f0b2713fa07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b89e38295f934a4785756a4741ab1055": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75a9f356c1574bf3ab38e73d0144b344": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12b0b3950df471bb5b822f1afce9046",
       "IPY_MODEL_acb8fdb3932945d4b07232dee71fface",
       "IPY_MODEL_568a368e8b094ec19c16f92281859c1c"
      ],
      "layout": "IPY_MODEL_182de626138f4fc5abec16510f997cf9"
     }
    },
    "c12b0b3950df471bb5b822f1afce9046": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1312213efa0348c8b426c32fd115fa5c",
      "placeholder": "​",
      "style": "IPY_MODEL_3bd67740fd3d41e9bbd6112e3417cc58",
      "value": ""
     }
    },
    "acb8fdb3932945d4b07232dee71fface": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f22ac599ac61405fb3fac039379f03f0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_076e6e7c43b74724a94383ee353dc0a1",
      "value": 1
     }
    },
    "568a368e8b094ec19c16f92281859c1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c22f6b739ca5473e8e612277dc267fa0",
      "placeholder": "​",
      "style": "IPY_MODEL_2edb0a13541a4dc79354be2ea3c6916f",
      "value": " 625/? [00:03&lt;00:00, 216.07it/s]"
     }
    },
    "182de626138f4fc5abec16510f997cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1312213efa0348c8b426c32fd115fa5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bd67740fd3d41e9bbd6112e3417cc58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f22ac599ac61405fb3fac039379f03f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "076e6e7c43b74724a94383ee353dc0a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c22f6b739ca5473e8e612277dc267fa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2edb0a13541a4dc79354be2ea3c6916f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
