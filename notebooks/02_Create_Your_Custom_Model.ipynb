{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9cf04",
   "metadata": {},
   "source": [
    "# How to Create Your Custom PyTorch Model\n",
    "\n",
    "The Fed-BioMed framework allows you to perform model training without changing your PyTorch model class completely. It only requires extra attributes and methods to train your model based on a federated approach.  In this tutorial, you will learn how to write/define your model in Fed-BioMed using the PyTorch framework.  \n",
    "\n",
    "**Note:** Before starting this tutorial we highly recommend you to follow the previous tutorial to understand the basics of Fed-BioMed. \n",
    "\n",
    "In this tutorial, you will learn,\n",
    "\n",
    "1. What is Fed-BioMed's training plan \n",
    "2. How to initialize your custom model\n",
    "3. How to create your `forward` method\n",
    "4. What is the method  `training_data` and how to make your custom PyTorch DataLoader to use in `tarning_data`.\n",
    "5. How to prepare your model file to make it executable by the nodes.\n",
    "\n",
    "\n",
    "\n",
    "During this tutorial, we will be working on Celaba (CelebaFaces) dataset. You can see details of the dataset [here](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). In the following sections, you will have the **instructions** for **downloading** and **configuring** Celeba dataset for Fed-BioMed framework.\n",
    "\n",
    "\n",
    "## 1. Fed-BioMed Training Plan\n",
    "\n",
    "In this section, you are going to learn how to write your custom training plan. \n",
    "\n",
    "### What is Training Plan?\n",
    "\n",
    "The training plan is the class that will be constructed by each node during every round of training. In short, it defines the attributes and methods of your network to be able to train your model. TorchTrainingPlan has been designed by considering the model class of the PyTorch framework. It inherits the class called TorchTrainingPlan which has been created for extending PyTorch `nn.Module`. For more details, you can visit documentation for [training plan](/user-guide/researcher/training-plan).  The following code snippet shows a basic training plan of Fed-BioMed for PyTorch.\n",
    "\n",
    "``` python\n",
    "class Net(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        # ....\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ...\n",
    "        return\n",
    "    \n",
    "    def training_data(self,  batch_size = 48):\n",
    "        # ...\n",
    "        return\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        # ...\n",
    "        return\n",
    "\n",
    "```\n",
    "\n",
    "### `__init__` Method of Training Plan \n",
    "\n",
    "`__init__` method of the training plan is where you initialize your neural network layers same as PyTorch. This is also where you can initialize model arguments for defining layers of neural networks. In addition, you can define extra dependencies that you will need in your model class using the `add_dependency` method which comes from `TorchTrainingPlan`. \n",
    "\n",
    "\n",
    "As mentioned before, we will be working on a classification model on the CelebA image dataset. The model will be able to predict if the person smiles or not. Therefore, you need to define the network's layers for this classification problem.\n",
    "\n",
    "\n",
    "``` python\n",
    "def __init__(self, model_args: dict = {}):\n",
    "\n",
    "    super(Net, self).__init__(model_args)\n",
    "    # Convolutional layers\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "    self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "    self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "    self.dropout1 = nn.Dropout(0.25)\n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    # Classifier\n",
    "    self.fc1 = nn.Linear(3168, 128)\n",
    "    self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "    deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "            \"from torchvision import transforms\",\n",
    "            \"import pandas as pd\",\n",
    "            \"from PIL import Image\",\n",
    "            \"import os\",\n",
    "            \"import numpy as np\"]\n",
    "\n",
    "    self.add_dependency(deps)\n",
    "\n",
    "```\n",
    "\n",
    "### `forward()` Method \n",
    "\n",
    "Next, you should define the forward method using the layers that are defined in `__init__`. In the forward method, we create the forwarding process from input layer to output layer of network. \n",
    "\n",
    "``` python\n",
    "def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output  \n",
    "\n",
    "```\n",
    "\n",
    "### `training_data() and Custom Dataset`\n",
    "\n",
    "`training_data` is an important part of the model class. Since the training plan will be performed in different nodes, `training_data` should process and return the data stored in the node. During each round of training, every node builds your model; gets the data using the method `training_data`, and performs the `training_step`.\n",
    "\n",
    "The dataset that we propose to use for training is a custom image dataset. Therefore, you need to define a custom Dataset for [PyTorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). To do so, a new class in the training plan using PyTorch's Dataset module has to be created.\n",
    "\n",
    "Thanks to the Dataset module we don't load the full data of the images, we retrieve the image with the `__getitem__`. This doesn't impact the ram usage as much as loading every image in the dataset.\n",
    "\n",
    "```python\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "\n",
    "            # Read the csv file that includes classes for each image\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir, self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "Now, you need to define a `training_data` method that will create a Pytorch DataLoader using the custom `CelebaDataset` class.\n",
    "\n",
    "```python\n",
    "    def training_data(self,  batch_size = 48):\n",
    "        # The training_data creates the Dataloader to be used for training in the general class Torchnn of Fed-BioMed\n",
    "        dataset = self.CelebaDataset(self.dataset_path + \"/target.csv\", self.dataset_path + \"/data/\")\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = DataLoader(dataset, **train_kwargs)\n",
    "        return data_loader\n",
    "```\n",
    "\n",
    "\n",
    "### `training_step()`\n",
    "\n",
    "The last method that needs to be defined is the `training_step`. This method is responsible of executing the forward method and calculating the loss value for the backward process of the network. \n",
    "\n",
    "```python\n",
    "def training_step(self, data, target): \n",
    "    output = self.forward(data)\n",
    "    loss   = torch.nn.functional.nll_loss(output, target)\n",
    "    return loss\n",
    "```\n",
    "\n",
    "You are now ready to create your training plan class. All you need to do is to locate every method that has been explained in the previous sections. In the next steps we will;\n",
    "\n",
    "1. download the CelebA dataset and deploy it on the nodes\n",
    "2. define our complete model and save it as a python file\n",
    "3. create an experiment and run it\n",
    "4. evaluate our model using a test dataset\n",
    "\n",
    "\n",
    "## 2.Configuring Nodes \n",
    "\n",
    "We will be working with [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) (CelebFaces) dataset. Therefore, please visit [here](https://drive.google.com/drive/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8?resourcekey=0-5BR16BdXnb8hVj6CNHKzLg) and download the files `img/img_align_celeba.zip` and `Anno/list_attr_celeba.txt`. After the download operation is completed;\n",
    "\n",
    "- Please go to `./notebooks/data/Celeba` in Fed-BioMed project. \n",
    "- Create `Celeba_raw/raw` directory and copy the `list_attr_celeba.txt` file.\n",
    "- Extract the zip file `img_align_celeba.zip`\n",
    "\n",
    "Your folder should be like the tree below;\n",
    "\n",
    "```\n",
    "Celeba\n",
    "    README.md\n",
    "    create_node_data.py    \n",
    "    .gitignore\n",
    " \n",
    "    Celeba_raw\n",
    "        raw\n",
    "            list_attr_celeba.txt\n",
    "            img_align_celeba.zip\n",
    "            img_align_celeba\n",
    "              lots of images \n",
    "```\n",
    "Now, the dataset has to be processed and splitted to create three distinct datasets for Node 1, Node 2, and Node 3. You can do it easily by running the following script in your notebook. Please make sure that you start your notebook in the `notebooks` directory of fedbiomed. Otherwise, the path that is defined in the following scripts may not work. If you are working in a different directory please make sure that you define the correct path in the following example.\n",
    "\n",
    "Running the following scripts might take some time, please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Celeba folder\n",
    "parent_dir = os.path.join(\".\", \"data\", \"Celeba\") \n",
    "celeba_raw_folder = os.path.join(\"Celeba_raw\", \"raw\")\n",
    "img_dir = os.path.join(parent_dir, celeba_raw_folder, 'img_align_celeba') + os.sep\n",
    "out_dir = os.path.join(\".\", \"data\", \"Celeba\", \"celeba_preprocessed\")\n",
    "\n",
    "# Read attribute CSV and only load Smilling column\n",
    "df = pd.read_csv(os.path.join(parent_dir, celeba_raw_folder, 'list_attr_celeba.txt'),\n",
    "                 sep=\"\\s+\", skiprows=1, usecols=['Smiling'])\n",
    "\n",
    "# data is on the form : 1 if the person is smiling, -1 otherwise. we set all -1 to 0 for the model to train faster\n",
    "df.loc[df['Smiling'] == -1, 'Smiling'] = 0\n",
    "\n",
    "# Split csv in 3 part\n",
    "length = len(df)\n",
    "data_node_1 = df.iloc[:int(length/3)]\n",
    "data_node_2 = df.iloc[int(length/3):int(length/3) * 2]\n",
    "data_node_3 = df.iloc[int(length/3) * 2:]\n",
    "\n",
    "# Create folder for each node\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_1\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_1\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_2\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_2\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_3\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_3\", \"data\"))\n",
    "\n",
    "# Save each node's target CSV to the corect folder\n",
    "data_node_1.to_csv(os.path.join(out_dir, 'data_node_1', 'target.csv'), sep='\\t')\n",
    "data_node_2.to_csv(os.path.join(out_dir, 'data_node_2', 'target.csv'), sep='\\t')\n",
    "data_node_3.to_csv(os.path.join(out_dir, 'data_node_3', 'target.csv'), sep='\\t')\n",
    "\n",
    "# Copy all images of each node in the correct folder\n",
    "for im in data_node_1.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir,\"data_node_1\", \"data\", im))\n",
    "print(\"data for node 1 succesfully created\")\n",
    "\n",
    "for im in data_node_2.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir, \"data_node_2\", \"data\", im))\n",
    "print(\"data for node 2 succesfully created\")\n",
    "\n",
    "for im in data_node_3.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir, \"data_node_3\", \"data\", im))\n",
    "print(\"data for node 3 succesfully created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabc12a",
   "metadata": {},
   "source": [
    "Now if you go to the `${FEDBIOMED_DIR}/notebooks/data/Celaba` directory you can see the folder called `celeba_preprocessed`. There will be three different folders that contain an image dataset for 3 nodes. The next step will be configuring the nodes and adding these datasets. We will configure only two nodes. The dataset for the third node is going to be used for testing. \n",
    "\n",
    "\n",
    "Create 2 nodes for training :  \n",
    " - `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config node1.ini start`\n",
    " - `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config node2.ini start`  \n",
    " \n",
    "Add data to each node :  \n",
    " - `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config node1.ini add`\n",
    " - `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config node2.ini add`\n",
    " \n",
    "**Note**: `${FEDBIOMED_DIR}` is a path relative to based directory of the cloned Fed-BioMed repository. You can set it by running command `export FEDBIOMED_DIR=/path/to/fedbiomed`. This is not required for Fed-BioMed to work but enables you to run the tutorials more easily. \n",
    " \n",
    "### 2.1. Configuration Steps\n",
    "\n",
    "It is necessary to previously configure at least a node:\n",
    "1. `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config (ini file) add`\n",
    "  * Select option 3 (images) to add an image dataset to the node\n",
    "  * Add a name and the tag for the dataset (tag should contain **'#celeba'** as it is the tag used for this training) and finally add the description\n",
    "  * Pick a data folder from the 3 generated datasets inside `data/Celeba/celeba_preprocessed` (eg: `data_node_1`)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config (ini file) list`\n",
    "3. Run the node using `${FEDBIOMED_DIR}/scripts/fedbiomed_run node config <ini file> start`. Wait until you get `Starting task manager`. it means you are online.\n",
    "\n",
    "After these steps, you are ready to train your classification model over two different nodes. \n",
    "\n",
    "## 3. Defining Custom PyTorch Model\n",
    "\n",
    "You should set a file path where you want to save your model file. By default, in the fedbiomed.researcher.environ path is defined as 'tmp' in the base fedbiomed directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "import os\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+os.sep)\n",
    "model_file = os.path.join(tmp_dir_model.name, 'CelebaClass.py') # name of the model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd2931",
   "metadata": {},
   "source": [
    "Now, it is time to create our `Net` class based on the methods that have been explained in the previous section. Please do not forget to add `%%writefile \"$model_file\"` command at the beginning of the following cell. This command allows to write the script into the file. Thanks to that, experiment can access the model file and uploads it to the file repository to make it accessible for the nodes. The nodes get the model file from the file repository and do the training part based on the model defined in the `Net` class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0929ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from  fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class Net(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(Net, self).__init__(model_args)\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        # Classifier\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "        deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "                \"from torchvision import transforms\",\n",
    "                \"import pandas as pd\",\n",
    "               \"from PIL import Image\",\n",
    "               \"import os\",\n",
    "               \"import numpy as np\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "        \n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "    def training_data(self,  batch_size = 48):\n",
    "        # The training_data creates the Dataloader to be used for training in the general class Torchnn of fedbiomed\n",
    "        dataset = self.CelebaDataset(os.path.join(self.dataset_path, \"target.csv\"), \n",
    "                                     os.path.join(self.dataset_path, \"data\")+os.sep)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = DataLoader(dataset, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8d887",
   "metadata": {},
   "source": [
    "This group of arguments corresponds respectively to:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node-side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node-side.\n",
    "\n",
    "**Note:** Typos and/or lack of positional (required) arguments might raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': 32, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09392303",
   "metadata": {},
   "source": [
    "## 4. Training Federated Model\n",
    "\n",
    "To provide training orchestration over two nodes we need to difene an experiment. The experiment:\n",
    "\n",
    "- searches nodes serving data for the `tags`, \n",
    "- define the local training on nodes with the model saved in `model_path`, and federate all local updates at each round with `aggregator`\n",
    "- runs training for `round_limit`.\n",
    "\n",
    "You can visit [user guide](/user-guide/researcher/experiment) to know much more about experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed132c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#celeba']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_path=model_file,\n",
    "                 model_class='Net',\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38721584",
   "metadata": {},
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes. While the experiment runs you can open the terminals where you have started the nodes and see the training progress. However, the loss values obtained from each node during the training will be printed as output in real time. Since we are working on an image dataset, training might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e34946",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227e429",
   "metadata": {},
   "source": [
    "### Loading Training Parameters\n",
    "\n",
    "After all the rounds have been completed, you retrieve the aggregated parameters from the last round and load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe862bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model = exp.model_instance()\n",
    "fed_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e012d2",
   "metadata": {},
   "source": [
    "## 5. Testing Federated Model \n",
    "\n",
    "We will define a testing routine to extract the accuracy metrics on the testing dataset. We will use the dataset that has been extracted into `data_node_3`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec39d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    loader_size = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            # Only uses 10% of the dataset, results are similar but faster\n",
    "            if idx >= loader_size / 10:\n",
    "                pass\n",
    "                break\n",
    "\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/(data_loader.batch_size * idx)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b05f8b",
   "metadata": {},
   "source": [
    "We also need to define a custom Dataset class for the test dataset in order to load it using PyTorch's `DataLoader`. This will be the same class that has been already defined in the training plan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset_path = \"./data/Celeba/celeba_preprocessed/data_node_3\"\n",
    "\n",
    "class CelebaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, txt_path, img_dir, transform=None):\n",
    "        df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_path = txt_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Smiling'].values\n",
    "        self.transform = transform\n",
    "        print(\"celeba dataset finished\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "\n",
    "dataset = CelebaDataset(os.path.join(test_dataset_path, \"target.csv\"),\n",
    "                        os.path.join(test_dataset_path, \"data\") +os.sep)\n",
    "train_kwargs = {'batch_size': 128, 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42993d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_federated = testing_Accuracy(fed_model, data_loader)\n",
    "acc_federated[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246bb08",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this tutorial, running a custom model on Fed-BioMed using the PyTorch framework has been explained. Because the examples are designed for the development environment, we have been running nodes in the same host machine. In production, the nodes that you need to use to train your model will serve in remote servers. Since Fed-BioMed is still in the development phase, in future there might be updates in the function and the methods of these tutorials. Therefore, please keep you updated from our [GitLab]() repository. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
